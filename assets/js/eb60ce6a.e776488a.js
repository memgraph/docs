"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[17804],{3905:function(e,a,t){t.d(a,{Zo:function(){return p},kt:function(){return u}});var n=t(67294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function s(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?s(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)t=s[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)t=s[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var m=n.createContext({}),l=function(e){var a=n.useContext(m),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},p=function(e){var a=l(e.components);return n.createElement(m.Provider,{value:a},e.children)},d={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},g=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,s=e.originalType,m=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),g=l(t),u=r,c=g["".concat(m,".").concat(u)]||g[u]||d[u]||s;return t?n.createElement(c,o(o({ref:a},p),{},{components:t})):n.createElement(c,o({ref:a},p))}));function u(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var s=t.length,o=new Array(s);o[0]=g;var i={};for(var m in a)hasOwnProperty.call(a,m)&&(i[m]=a[m]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var l=2;l<s;l++)o[l]=t[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}g.displayName="MDXCreateElement"},1890:function(e,a,t){t.r(a),t.d(a,{assets:function(){return p},contentTitle:function(){return m},default:function(){return u},frontMatter:function(){return i},metadata:function(){return l},toc:function(){return d}});var n=t(87462),r=t(63366),s=(t(67294),t(3905)),o=["components"],i={id:"overview",title:"Importing data from Kafka and Redpanda streams",sidebar_label:"Kafka and Redpanda streams",slug:"/import-data/kafka-redpanda",pagination_prev:"import-data/overview"},m=void 0,l={unversionedId:"import-data/kafka/overview",id:"import-data/kafka/overview",title:"Importing data from Kafka and Redpanda streams",description:"Memgraph can natively ingest streaming data from upstream sources using [Apache",source:"@site/docs/import-data/kafka/overview.md",sourceDirName:"import-data/kafka",slug:"/import-data/kafka-redpanda",permalink:"/docs/memgraph/next/import-data/kafka-redpanda",editUrl:"https://github.com/memgraph/docs/tree/master/docs/import-data/kafka/overview.md",tags:[],version:"current",frontMatter:{id:"overview",title:"Importing data from Kafka and Redpanda streams",sidebar_label:"Kafka and Redpanda streams",slug:"/import-data/kafka-redpanda",pagination_prev:"import-data/overview"},previous:{title:"Import data overview",permalink:"/docs/memgraph/next/import-data"}},p={},d=[{value:"1. Start Memgraph",id:"1-start-memgraph",level:2},{value:"2. Define a transformation module",id:"2-define-a-transformation-module",level:2},{value:"JSON",id:"json",level:3},{value:"Avro",id:"avro",level:3},{value:"Protobuf",id:"protobuf",level:3},{value:"3. Load modules",id:"3-load-modules",level:2},{value:"Load modules while the instance is already running",id:"load-modules-while-the-instance-is-already-running",level:3},{value:"Check the transformation module",id:"check-the-transformation-module",level:3},{value:"4. Create a stream in Memgraph",id:"4-create-a-stream-in-memgraph",level:2},{value:"5. Start ingesting data from the stream",id:"5-start-ingesting-data-from-the-stream",level:2},{value:"Logs",id:"logs",level:2},{value:"What&#39;s next?",id:"whats-next",level:2}],g={toc:d};function u(e){var a=e.components,i=(0,r.Z)(e,o);return(0,s.kt)("wrapper",(0,n.Z)({},g,i,{components:a,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"Memgraph can natively ingest streaming data from upstream sources using ",(0,s.kt)("a",{parentName:"p",href:"https://kafka.apache.org"},"Apache\nKafka"),", ",(0,s.kt)("a",{parentName:"p",href:"https://www.confluent.io"},"Confluent Platform"),"\nand ",(0,s.kt)("a",{parentName:"p",href:"https://redpanda.com/"},"Redpanda"),"."),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/tutorials/graph-stream-processing-with-kafka"},(0,s.kt)("img",{parentName:"a",src:"https://img.shields.io/static/v1?label=Related&message=Tutorial&color=008a00&style=for-the-badge",alt:"Related - Tutorial"}))," ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/how-to-guides/streams/manage-streams"},(0,s.kt)("img",{parentName:"a",src:"https://img.shields.io/static/v1?label=Related&message=How-to&color=blue&style=for-the-badge",alt:"Related - How to"}))," ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/reference-guide/streams"},(0,s.kt)("img",{parentName:"a",src:"https://img.shields.io/static/v1?label=Related&message=Reference%20Guide&color=yellow&style=for-the-badge",alt:"Related - Reference Guide"}))),(0,s.kt)("p",null,"To import data using streams, you must:"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"#1-start-memgraph"},"Start Memgraph")," "),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"#2-define-a-transformation-module"},"Define a transformation module")," "),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"#3-load-modules"},"Load modules")," "),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"#4-create-a-stream-in-memgraph"},"Create a stream in Memgraph")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"#5-start-ingesting-data-from-the-stream"},"Start ingesting data from the stream"))),(0,s.kt)("img",{src:t(59139).Z}),(0,s.kt)("h2",{id:"1-start-memgraph"},"1. Start Memgraph"),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"/memgraph/installation"},"Start Memgraph")," and ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/connect-to-memgraph"},"establish a\nconnection")," to the database."),(0,s.kt)("p",null,"If you are starting Memgraph using a Docker image and would like to access\nconfiguration files or logs, be sure to run the image with the following\nvolumes:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("inlineCode",{parentName:"li"},"-v mg_log:/var/log/memgraph")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("inlineCode",{parentName:"li"},"-v mg_etc:/etc/memgraph"))),(0,s.kt)("h2",{id:"2-define-a-transformation-module"},"2. Define a transformation module"),(0,s.kt)("p",null,"A transformation module is a user-defined module that receives data from a\nstream and returns processed data in the form of Cypher queries. The most common\nformats are:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("a",{parentName:"strong",href:"#json"},"JSON"))),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("a",{parentName:"strong",href:"#avro"},"Avro"))),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("a",{parentName:"strong",href:"#protobuf"},"Protobuf")))),(0,s.kt)("p",null,"Transformation modules can be written in either\n",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/reference-guide/streams/transformation-modules/api/python-api"},(0,s.kt)("strong",{parentName:"a"},"Python")),"\nor ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/reference-guide/streams/transformation-modules/api/c-api"},(0,s.kt)("strong",{parentName:"a"},"C")),"\nlanguages. Python transformation procedures can be written directly within Memgraph Lab, either\nin the ",(0,s.kt)("strong",{parentName:"p"},"Query Modules")," section, or as a part of the wizard when setting up\nstreams. "),(0,s.kt)("p",null,"The best practice is to have a dedicated topic for each message type in order to\nparse the data more efficiently. Each topic requires a separate procedure within\na single transformation module to handle the conversion. Below are\ntransformation examples of messages in different format. "),(0,s.kt)("p",null,"Once the transformation procedures have been written, the module needs to be\nloaded into Memgraph."),(0,s.kt)("h3",{id:"json"},"JSON"),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://www.json.org/json-en.html"},"JSON")," (JavaScript Object Notation) is an\nopen standard file format and data interchange format that uses human-readable\ntext to store and transmit data objects consisting of attribute-value pairs and\narrays (or other serializable values). It is a common data format with a diverse\nrange of functionality in data interchange, including communication of web\napplications with servers."),(0,s.kt)("p",null,"Let's assume we have the following schemas coming out of three topics:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'person = {\n        "id" : int,\n        "name": str,\n        "address" : str,\n        "mail": str,\n    }\ncompany = {\n        "id" : int,\n        "name" : str,\n        "address" : str,\n        "mail": str,\n    }\nworks_at = {\n            "person_id"  : int,\n            "company_id" : int,\n            "start_date" : date,\n        }\n')),(0,s.kt)("p",null,"The procedures within the Python transformation module that will transform the incoming\ndata into Cypher query would look like this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'import mgp\nimport json\n\n@mgp.transformation\ndef person_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n    for i in range(messages.total_messages()):\n        message = messages.message_at(i)\n        message_json = json.loads(message.payload())\n        result_queries.append(mgp.Record (\n                query=f\'\'\'MERGE (p:Person {{ id: ToInteger({message_json["id"]}), name: "{message_json["name"]}",\n                address: "{message_json["address"]}", mail: "{message_json["mail"]}" }})\'\'\' ,\n                parameters=None\n            ))\n    return result_queries\n\n@mgp.transformation\ndef company_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n    for i in range(messages.total_messages()):\n        message = messages.message_at(i)\n        message_json = json.loads(message.payload())\n        result_queries.append(mgp.Record (\n                query=f\'\'\'MERGE (c:Company {{ id: ToInteger({message_json["id"]}), name: "{message_json["name"]}",\n                address: "{message_json["address"]}", mail: "{message_json["mail"]}" }})\'\'\' ,\n                parameters=None\n            ))\n    return result_queries\n\n@mgp.transformation\ndef employees_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n\n    for i in range(messages.total_messages()):\n        message = messages.message_at(i)\n        message_json = json.loads(message.payload())\n        result_queries.append(mgp.Record (\n                query=f\'\'\'MATCH (p:Person ), (c:Company) \n                WHERE p.id = "{message_json["person_id"]}" AND c.id = "{message_json["company_id"]}" \n                MERGE (p)-[WORKS_AT: {{start_date: date({message_json["start_date"]})}}]->(c)\'\'\'  ,\n                parameters=None\n            ))\n\n    return result_queries\n')),(0,s.kt)("p",null,"Upon creating three separate streams in Memgraph (one for each topic), and\ningesting the data, the graph schema looks like this:"),(0,s.kt)("img",{src:t(34323).Z,height:"300px"}),(0,s.kt)("p",null,"If you need help writing transformation modules, check out ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/tutorials/graph-stream-processing-with-kafka#2-create-a-transformation-module"},"the tutorial on\nwriting modules in\nPython"),",\nand ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/reference-guide/streams/transformation-modules/api/c-api#transformation-module-example"},"an example of a C transformation\nprocedure"),". "),(0,s.kt)("h3",{id:"avro"},"Avro"),(0,s.kt)("p",null,"If you want to import your data in Memgraph using Apache Avro serialization, you\nneed to know the ",(0,s.kt)("a",{parentName:"p",href:"https://avro.apache.org/docs/current/gettingstartedpython.html#Defining+a+schema"},"Avro\nschema"),"\nof your data. This is necessary for deserializing the data. Each schema contains\na single schema definition, so there should be a separate schema for each data\nrepresentation you want to import into Memgraph."),(0,s.kt)("p",null,"Avro data types will be flexibly mapped to the target schema, that is, Avro and\nopenCypher types do not need to match exactly. Use the table below for data type\nmappings:"),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null},"Avro Data Type"),(0,s.kt)("th",{parentName:"tr",align:null},"Cypher Casting Function"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"bool"),(0,s.kt)("td",{parentName:"tr",align:null},"toBoolean")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"float"),(0,s.kt)("td",{parentName:"tr",align:null},"toFloat")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"int"),(0,s.kt)("td",{parentName:"tr",align:null},"toInteger")))),(0,s.kt)("p",null,"Let's assume we have the following schemas coming out of three topics:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'profile_schema = """ {\n    "namespace": "example.avro",\n    "name": "Person",\n    "type": "record",\n    "fields": [\n        {"name": "id", "type": "int"},\n        {"name": "name", "type": "string"},\n        {"name": "address", "type": "string"}\n        {"name": "mail", "type": "string"},\n    ]\n}"""\n\ncompany_schema = """{\n    "namespace": "example.avro",\n    "name": "Company",\n    "type": "record",\n    "fields": [\n        {"name": "id", "type": "int"},\n        {"name": "name", "type": "string"},\n        {"name": "address", "type": "string"}\n        {"name": "mail", "type": "string"},\n    ]\n} """\n\nworks_at_schema = """ {\n    "namespace": "example.avro",\n    "name": "Works_At",\n    "type": "record",\n    "fields": [\n        {"name": "person_id", "type": "int"},\n        {"name": "company_id", "type": "int"}\n        {"name": "start_date", "type": "date"}\n    ]\n}\n"""\n')),(0,s.kt)("p",null,"Data received by the Memgraph consumer is a byte array and needs to be\ndeserialized. The following method will deserialize data with the help of\nConfluent Kafka:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from confluent_kafka.schema_registry import SchemaRegistryClient\nfrom confluent_kafka.schema_registry.avro import AvroDeserializer\n\ndef process_record_confluent(record: bytes, src: SchemaRegistryClient, schema: str):\n    deserializer = AvroDeserializer(schema_str=schema, schema_registry_client=src)\n    return deserializer(record, None) # returns dict\n\n")),(0,s.kt)("p",null,"The procedures within the Python transformation module that will transform the incoming\ndata into Cypher query would look like this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'import mgp\n\n@mgp.transformation\ndef person_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n\n    for i in range(messages.total_messages()):\n        message_avro = messages.message_at(i)\n        msg_value = message_avro.payload()\n        message = process_record_confluent(msg_value, src= SchemaRegistryClient({\'url\': \'http://localhost:8081\'}), schema=profile_schema)\n        result_queries.append(mgp.Record (\n                query=f\'\'\'MERGE (p:Person {{ id: ToInteger({message["id"]}), name: "{message["name"]}", address: "{message["address"]}", mail: "{message["mail"]}" }})\'\'\' ,\n                parameters=None\n            ))\n\n    return result_queries\n\n@mgp.transformation\ndef company_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n\n    for i in range(messages.total_messages()):\n        message_avro = messages.message_at(i)\n        msg_value = message_avro.payload()\n        message = process_record_confluent(msg_value, src= SchemaRegistryClient({\'url\': \'http://localhost:8081\'}), schema=profile_schema)\n        result_queries.append(mgp.Record (\n                query=f\'\'\'MERGE (c:COmpany {{ id: ToInteger({message["id"]}), name: "{message["name"]}", address: "{message["address"]}", mail: "{message["mail"]}" }})\'\'\' ,\n                parameters=None\n            ))\n\n    return result_queries\n\n@mgp.transformation\ndef company_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n\n    for i in range(messages.total_messages()):\n        message_avro = messages.message_at(i)\n        msg_value = message_avro.payload()\n        message = process_record_confluent(msg_value, src= SchemaRegistryClient({\'url\': \'http://localhost:8081\'}), schema=profile_schema)\n        result_queries.append(mgp.Record (\n                query=f\'\'\'MATCH (p:Person ), (c:Company) \n                WHERE p.id = "{message["person_id"]}" AND c.id = "{message["company_id"]}" \n                MERGE (p)-[WORKS_AT: {{start_date: date({message["start_date"]})}}]->(c)\'\'\'  ,\n                parameters=None\n            ))\n\n    return result_queries\n\n')),(0,s.kt)("p",null,"Upon creating three separate streams in Memgraph (one for each topic), and ingesting the data, the\ngraph schema looks like this:"),(0,s.kt)("img",{src:t(34323).Z,height:"300px"}),(0,s.kt)("h3",{id:"protobuf"},"Protobuf"),(0,s.kt)("p",null,"Similar to Apache Avro,\n",(0,s.kt)("a",{parentName:"p",href:"https://developers.google.com/protocol-buffers"},"Protobuf")," is a method of\nserializing structured data. A message format is defined in a ",(0,s.kt)("inlineCode",{parentName:"p"},".proto")," file, and\nfrom it you can generate code in many languages, including Java, Python, C++,\nC#, Go, and Ruby. Unlike Avro, Protobuf does not serialize schema with the\nmessage. In order to deserialize the message, you need the schema in the\nconsumer. A benefit of working with Protobuf is the option to define multiple\nmessages in one ",(0,s.kt)("inlineCode",{parentName:"p"},".proto")," file."),(0,s.kt)("p",null,"Let's assume we have the following schemas coming out of three topics:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-protobuf"},'syntax = "proto3";\n\nmessage Person {\n    int64 id = 1;\n    string name = 2;\n    string address = 3;\n    string mail = 4;\n}\n\nmessage Company {\n    int64 id = 1;\n    string name = 2;\n    string address = 3;\n    string mail = 4;\n}\n\nmessage WorksAt {\n    int64 person_id = 1;\n    int64 company_id = 2;\n    string start_date = 3;\n}\n\n')),(0,s.kt)("p",null,"These schemas translate into the ",(0,s.kt)("inlineCode",{parentName:"p"},".proto")," file.\nBefore making your transformation script, it is necessary to ",(0,s.kt)("a",{parentName:"p",href:"https://developers.google.com/protocol-buffers/docs/pythontutorial#compiling-your-protocol-buffers"},"generate\ncode"),"\nfrom the ",(0,s.kt)("inlineCode",{parentName:"p"},".proto")," file."),(0,s.kt)("p",null,"Data received by the Memgraph consumer is a byte array and needs to be\ndeserialized. The following method will help you deserialize your data with the\nhelp of Confluent Kafka:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from confluent_kafka.schema_registry import SchemaRegistryClient\nfrom confluent_kafka.schema_registry.protobuf import ProtobufDeserializer\n\nimport person_pb2 # proto file compiled into Python module\n\ndef process_record_protobuf(record: bytes, message_type: obj) -> dict:\n    deserializer = ProtobufDeserializer(message_type)\n    return deserializer(record, None)\n")),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"message_type")," corresponds to the message defined in ",(0,s.kt)("inlineCode",{parentName:"p"},".proto")," file. This method\nshould be added to the transformation module."),(0,s.kt)("p",null,"The procedures within the Python transformation module that will transform the incoming\ndata into Cypher query would look like this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import mgp\n\n@mgp.transformation\ndef person_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n    for i in range(messages.total_messages()):\n        message_pb = messages.message_at(i)\n        msg_value = message_pb.payload()\n        message = process_record_protobuf(msg_value, person_pb2.Person)\n        result_queries.append(mgp.Record (\n                query=f'''MERGE (p:Person {{ id: ToInteger({message.id}), name: \"{message.name}\", address: \"{message.address}\", mail: \"{messag.mail}\" }})''' ,\n                parameters=None\n            ))\n\n    return result_queries\n\n@mgp.transformation\ndef company_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n    for i in range(messages.total_messages()):\n        message_pb = messages.message_at(i)\n        msg_value = message_pb.payload()\n        message = process_record_protobuf(msg_value, person_pb2.Person)\n        result_queries.append(mgp.Record (\n                query=f'''MERGE (c:Copany {{ id: ToInteger({message.id}), name: \"{message.name}\", address: \"{message.address}\", mail: \"{messag.mail}\" }})''' ,\n                parameters=None\n            ))\n\n    return result_queries\n\n@mgp.transformation\ndef company_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n    for i in range(messages.total_messages()):\n        message_pb = messages.message_at(i)\n        msg_value = message_pb.payload()\n        message = process_record_protobuf(msg_value, person_pb2.Person)\n        result_queries.append(mgp.Record (\n                query=f'''MATCH (p:Person ), (c:Company) \n                WHERE p.id = \"{message.person_id}\" AND c.id = \"{message.company_id}\" \n                MERGE (p)-[WORKS_AT: {{start_date: date({message.start_date})}}]->(c)'''  ,\n                parameters=None\n            ))\n\n    return result_queries\n")),(0,s.kt)("p",null,"Upon creating three separate streams in Memgraph (one for each topic), and ingesting the data, the\ngraph schema looks like this:"),(0,s.kt)("img",{src:t(34323).Z,height:"300px"}),(0,s.kt)("h2",{id:"3-load-modules"},"3. Load modules"),(0,s.kt)("p",null,"When started, Memgraph will automatically attempt to load the transformation\nmodules from all ",(0,s.kt)("inlineCode",{parentName:"p"},"*.so")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"*.py")," files it finds in the default\n",(0,s.kt)("inlineCode",{parentName:"p"},"/usr/lib/memgraph/query_modules")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"/memgraph/internal_modules")," directories.\nIf you are using Docker, you need to ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/how-to-guides/work-with-docker#how-to-copy-files-from-and-to-a-docker-container"},"transfer the transformation module file\ninto the Docker\ncontainer"),"."),(0,s.kt)("p",null,"You can point to a different directory by changing or extending the\n",(0,s.kt)("inlineCode",{parentName:"p"},"--query-modules-directory")," flag in the main configuration file\n(",(0,s.kt)("inlineCode",{parentName:"p"},"/etc/memgraph/memgraph.conf"),"). If you need help with changing the\nconfiguration file, check out the ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/how-to-guides/config-logs"},"how-to guide"),".\nYou can also define the flag within a command-line parameter when using Docker."),(0,s.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,s.kt)("div",{parentName:"div",className:"admonition-heading"},(0,s.kt)("h5",{parentName:"div"},(0,s.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,s.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,s.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,s.kt)("div",{parentName:"div",className:"admonition-content"},(0,s.kt)("p",{parentName:"div"},"Please remember that if you are using Memgraph Platform image, you should pass\nconfiguration flags within MEMGRAPH environment variable (e.g. ",(0,s.kt)("inlineCode",{parentName:"p"},'docker run -p\n7687:7687 -p 3000:3000 -p 7444:7444 -e MEMGRAPH="--log-level=TRACE"\nmemgraph/memgraph-platform'),") and if you are using any other image, you should\npass them as arguments after the image name (e.g., ",(0,s.kt)("inlineCode",{parentName:"p"},"... memgraph/memgraph-mage\n--log-level=TRACE --query-modules-directory=path/path"),")."))),(0,s.kt)("h3",{id:"load-modules-while-the-instance-is-already-running"},"Load modules while the instance is already running"),(0,s.kt)("p",null,"If the transformation module has been added to the directory while the Memgraph\ninstance was already running, you need to load it manually by using the\nfollowing query:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL mg.load('transformation_name');\n")),(0,s.kt)("p",null,"or"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL mg.load_all();\n")),(0,s.kt)("h3",{id:"check-the-transformation-module"},"Check the transformation module"),(0,s.kt)("p",null,"If you want to check if your module has properly loaded in Memgraph run:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL mg.transformations() YIELD *;\n")),(0,s.kt)("p",null,"You should see an output similar to the following:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},'+------------------+------------------------------------+---------------------------------------------------------+\n| is_editable      | name                               | path                                                    |\n+------------------+------------------------------------+---------------------------------------------------------|\n| `true`           | "transformation_module.procedure"  | `/memgraph/internal_modules/transformation_module.py    |\n+------------------+------------------------------------+---------------------------------------------------------+\n')),(0,s.kt)("h2",{id:"4-create-a-stream-in-memgraph"},"4. Create a stream in Memgraph"),(0,s.kt)("p",null,"To connect Memgraph to stream, you need to create a stream in Memgraph. First,\nmake sure the stream and Memgraph are running, and there is a topic available.\nThen, make sure the transformation module is loaded."),(0,s.kt)("p",null,"Create the stream in Memgraph with the following query:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE KAFKA STREAM <stream_name>\nTOPICS <topic1>[, <topic2>, ...]\nTRANSFORM <transformation_module.transformation_procedure>\n[BOOTSTRAP_SERVERS <bootstrap servers>];\n")),(0,s.kt)("p",null,"You need to create one stream for each topic and procedure you have."),(0,s.kt)("p",null,"If you are using Memgraph Lab, you can also create streams using a wizard in the\n",(0,s.kt)("strong",{parentName:"p"},"Streams")," section. "),(0,s.kt)("p",null,"For more options and information about the ",(0,s.kt)("inlineCode",{parentName:"p"},"CREATE .. STREAM")," query and all the\nother options regarding streams, check out the ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/reference-guide/streams"},"reference\nguide"),"."),(0,s.kt)("h2",{id:"5-start-ingesting-data-from-the-stream"},"5. Start ingesting data from the stream"),(0,s.kt)("p",null,"The previous query only created the streams. To start streaming data, execute\nthe following query:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"START STREAM stream_name;\n")),(0,s.kt)("p",null,"or"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"START ALL STREAMS;\n")),(0,s.kt)("p",null,"Your data should be slowly arriving in your Memgraph instance. To check if\neverything is working, run the following query:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"CHECK STREAM stream_name;\n")),(0,s.kt)("p",null,"or"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-cypher"},"SHOW STREAMS;\n")),(0,s.kt)("p",null,"You can also check the node counter in ",(0,s.kt)("strong",{parentName:"p"},"Memgraph Lab")," (",(0,s.kt)("strong",{parentName:"p"},"Overview tab"),") to\nsee if new nodes and relationships are arriving."),(0,s.kt)("p",null,"If you are using Memgraph Lab, you can start the stream and check the status of\nthe stream in the ",(0,s.kt)("strong",{parentName:"p"},"Streams")," section. "),(0,s.kt)("p",null,"For all the other stream commands, check out ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/reference-guide/streams"},"the reference\nguide"),"."),(0,s.kt)("h2",{id:"logs"},"Logs"),(0,s.kt)("p",null,"Errors and notifications regarding streams are contained in Memgraph's log files\nwhich can be found at ",(0,s.kt)("inlineCode",{parentName:"p"},"/var/log/memgraph/memgraph_<date>.log")," Look for the name\nof your stream in the log file to find the error. You can use the ",(0,s.kt)("inlineCode",{parentName:"p"},"grep")," command\nto search for the stream in the log file:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"grep '<stream_name>' /var/log/memgraph/memgraph_<date>.log\n")),(0,s.kt)("p",null,"If you are running Memgraph with Docker and want to see logs in Memgraph Lab, be\nsure to exposed the 7444 port when running the ",(0,s.kt)("inlineCode",{parentName:"p"},"docker run")," command."),(0,s.kt)("h2",{id:"whats-next"},"What's next?"),(0,s.kt)("p",null,"Take a look at the tutorial we made to help you ",(0,s.kt)("a",{parentName:"p",href:"/docs/memgraph/next/tutorials/graph-stream-processing-with-kafka"},"connect Memgraph and\nKafka"),". Learn more about the\nquery power of ",(0,s.kt)("a",{parentName:"p",href:"/cypher-manual"},"Cypher language"),", or check out ",(0,s.kt)("a",{parentName:"p",href:"/mage"},"MAGE")," -\nan open-source repository that contains graph algorithms and modules that can\nhelp you tackle the most interesting and challenging graph analytics problems.\nIf you are using ",(0,s.kt)("strong",{parentName:"p"},"Memgraph Lab"),", a visual user interface for running queries\nand visualizing graph data, you might be interested in the ",(0,s.kt)("a",{parentName:"p",href:"/memgraph-lab/graph-style-script-language"},"Graph Style Script\nlanguage")," that will help you bedazzle\nyour graphs. Above all, enjoy your graph database!"))}u.isMDXComponent=!0},34323:function(e,a,t){a.Z=t.p+"assets/images/kafka-graph-e4e8c68495826bbe558fbeadb1abc14d.png"},59139:function(e,a,t){a.Z=t.p+"assets/images/kafka-overview-4774e9a423387407d8ba09f2a83ca88a.png"}}]);
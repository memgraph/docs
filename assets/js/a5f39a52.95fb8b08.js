"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53771],{3905:function(e,t,n){n.d(t,{Zo:function(){return m},kt:function(){return g}});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},m=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),u=s(n),g=r,c=u["".concat(p,".").concat(g)]||u[g]||d[g]||l;return n?a.createElement(c,i(i({ref:t},m),{},{components:n})):a.createElement(c,i({ref:t},m))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,i=new Array(l);i[0]=u;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var s=2;s<l;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},85007:function(e,t,n){n.r(t),n.d(t,{Highlight:function(){return c},assets:function(){return u},contentTitle:function(){return m},default:function(){return h},frontMatter:function(){return s},metadata:function(){return d},toc:function(){return g}});var a=n(87462),r=n(63366),l=(n(67294),n(3905)),i=n(9877),o=n(58215),p=["components"],s={id:"temporal-graph-networks",title:"temporal_graph_networks",sidebar_label:"temporal_graph_networks"},m=void 0,d={unversionedId:"query-modules/python/temporal-graph-networks",id:"query-modules/python/temporal-graph-networks",title:"temporal_graph_networks",description:"docs-source",source:"@site/mage/query-modules/python/temporal-graph-networks.md",sourceDirName:"query-modules/python",slug:"/query-modules/python/temporal-graph-networks",permalink:"/docs/mage/query-modules/python/temporal-graph-networks",editUrl:"https://github.com/memgraph/docs/tree/master/mage/query-modules/python/temporal-graph-networks.md",tags:[],version:"current",frontMatter:{id:"temporal-graph-networks",title:"temporal_graph_networks",sidebar_label:"temporal_graph_networks"},sidebar:"mage",previous:{title:"set_cover",permalink:"/docs/mage/query-modules/python/set-cover"},next:{title:"tsp",permalink:"/docs/mage/query-modules/python/tsp"}},u={},g=[{value:"Abstract",id:"abstract",level:2},{value:"About the query module",id:"about-the-query-module",level:3},{value:"Usage",id:"usage",level:3},{value:"Implementation details",id:"implementation-details",level:3},{value:"Query module",id:"query-module",level:4},{value:"Processing one batch",id:"processing-one-batch",level:4},{value:"Procedures",id:"procedures",level:2},{value:"<code>set_params(params)</code>",id:"set_paramsparams",level:3},{value:"Input:",id:"input",level:4},{value:"Usage:",id:"usage-1",level:4},{value:"<code>update(edges)</code>",id:"updateedges",level:3},{value:"Input:",id:"input-1",level:4},{value:"Usage:",id:"usage-2",level:4},{value:"<code>get()</code>",id:"get",level:3},{value:"Output:",id:"output",level:4},{value:"Usage:",id:"usage-3",level:4},{value:"<code>set_eval()</code>",id:"set_eval",level:3},{value:"Usage:",id:"usage-4",level:4},{value:"<code>get_results()</code>",id:"get_results",level:3},{value:"Output:",id:"output-1",level:4},{value:"Usage:",id:"usage-5",level:4},{value:"<code>train_and_eval(num_epochs)</code>",id:"train_and_evalnum_epochs",level:3},{value:"Input:",id:"input-2",level:4},{value:"Output:",id:"output-2",level:4},{value:"Usage:",id:"usage-6",level:4},{value:"<code>predict_link_score(vertex_1, vertex_2)</code>",id:"predict_link_scorevertex_1-vertex_2",level:3},{value:"Input:",id:"input-3",level:4},{value:"Output:",id:"output-3",level:4},{value:"Usage:",id:"usage-7",level:4},{value:"Example",id:"example",level:2}],c=function(e){var t=e.children,n=e.color;return(0,l.kt)("span",{style:{backgroundColor:n,borderRadius:"2px",color:"#fff",padding:"0.2rem"}},t)},k={toc:g,Highlight:c};function h(e){var t=e.components,s=(0,r.Z)(e,p);return(0,l.kt)("wrapper",(0,a.Z)({},k,s,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,(0,l.kt)("a",{parentName:"p",href:"https://github.com/memgraph/mage/blob/main/python/tgn.py"},(0,l.kt)("img",{parentName:"a",src:"https://img.shields.io/badge/source-temporal_graph_networks-FB6E00?logo=github&style=for-the-badge",alt:"docs-source"}))),(0,l.kt)("h2",{id:"abstract"},"Abstract"),(0,l.kt)("p",null,"The ",(0,l.kt)("strong",{parentName:"p"},"temporal_graph_networks (TGNs)")," are a type of ",(0,l.kt)("a",{parentName:"p",href:"https://distill.pub/2021/gnn-intro/"},"graph neural network\n(GNN)")," for dynamic graphs. In recent years,\n",(0,l.kt)("strong",{parentName:"p"},"GNNs")," have become very popular due to their ability to perform a wide variety\nof machine learning tasks on graphs, such as link prediction, node\nclassification, and so on. This rise started with ",(0,l.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1609.02907.pdf"},"Graph convolutional networks\n(GCN)")," introduced by ",(0,l.kt)("em",{parentName:"p"},"Kipf et al."),",\nfollowed by ",(0,l.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1706.02216.pdf"},"GraphSAGE")," introduced by\n",(0,l.kt)("em",{parentName:"p"},"Hamilton et al."),", and recently a new method that introduces the ",(0,l.kt)("strong",{parentName:"p"},"attention\nmechanism")," to graphs was presented - ",(0,l.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1710.10903.pdf?ref=https://githubhelp.com"},"Graph attention networks\n(GAT)"),", by\n",(0,l.kt)("em",{parentName:"p"},"Veli\u010dkovi\u0107 et al"),". The last two methods offer a great possibility for inductive\nlearning. But they haven't been specifically developed to handle different\nevents occurring on graphs, such as ",(0,l.kt)("strong",{parentName:"p"},"node features updates"),", ",(0,l.kt)("strong",{parentName:"p"},"node\ndeletion"),", ",(0,l.kt)("strong",{parentName:"p"},"edge deletion")," and so on. These events happen regularly in\n",(0,l.kt)("strong",{parentName:"p"},"real-world")," examples such as the ",(0,l.kt)("a",{parentName:"p",href:"https://twitter.com/memgraphmage"},"Twitter\nnetwork"),", where users update their profile,\ndelete their profile or just unfollow another user."),(0,l.kt)("p",null,"In their work, Rossi et al. introduce ",(0,l.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2006.10637"},"Temporal graph\nnetworks"),", an architecture for machine\nlearning on streamed graphs, a rapidly-growing ML use case."),(0,l.kt)("h3",{id:"about-the-query-module"},"About the query module"),(0,l.kt)("p",null,"What we have got in this module:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"link prediction")," - train your ",(0,l.kt)("strong",{parentName:"li"},"TGN")," to predict new ",(0,l.kt)("strong",{parentName:"li"},"links/edges")," and\n",(0,l.kt)("strong",{parentName:"li"},"node classification")," - predict labels of nodes from graph structure and\n",(0,l.kt)("strong",{parentName:"li"},"node/edge")," features"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"graph attention layer")," embedding calculation and ",(0,l.kt)("strong",{parentName:"li"},"graph sum layer"),"\nembedding layer calculation"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"mean")," and ",(0,l.kt)("strong",{parentName:"li"},"last")," as message aggregators"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"mlp")," and ",(0,l.kt)("strong",{parentName:"li"},"identity(concatenation)")," as message functions"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"gru")," and ",(0,l.kt)("strong",{parentName:"li"},"rnn")," as memory updater"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"uniform")," temporal neighborhood sampler"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"memory")," store and ",(0,l.kt)("strong",{parentName:"li"},"raw message store"))),(0,l.kt)("p",null,"as introduced by ",(0,l.kt)("a",{parentName:"p",href:"https://emanuelerossi.co.uk/"},"Rossi et al."),"."),(0,l.kt)("p",null,"The following means ",(0,l.kt)("strong",{parentName:"p"},"you")," can use ",(0,l.kt)("strong",{parentName:"p"},"TGN")," to ",(0,l.kt)("strong",{parentName:"p"},"predict edges")," or perform\n",(0,l.kt)("strong",{parentName:"p"},"node classification")," tasks, with ",(0,l.kt)("strong",{parentName:"p"},"graph attention layer")," or ",(0,l.kt)("strong",{parentName:"p"},"graph sum\nlayer"),", by using either ",(0,l.kt)("strong",{parentName:"p"},"mean")," or ",(0,l.kt)("strong",{parentName:"p"},"last")," as message aggregator, ",(0,l.kt)("strong",{parentName:"p"},"mlp")," or\n",(0,l.kt)("strong",{parentName:"p"},"identity")," as message function, and finally ",(0,l.kt)("strong",{parentName:"p"},"gru")," or ",(0,l.kt)("strong",{parentName:"p"},"rnn")," as memory\nupdater."),(0,l.kt)("p",null,"In total, this gives ",(0,l.kt)("em",{parentName:"p"},"you")," ",(0,l.kt)("strong",{parentName:"p"},"2\u27152\u27152\u27152\u27152 options"),", that is, ",(0,l.kt)("strong",{parentName:"p"},"32")," options to\nexplore on your graph! \ud83d\ude04"),(0,l.kt)("p",null,"If you want to explore our implementation, jump to\n",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage"},"github/memgraph/mage"))," and find\n",(0,l.kt)("inlineCode",{parentName:"p"},"python/tgn.py"),". You can also jump to the ",(0,l.kt)("a",{parentName:"p",href:"https://memgraph.com/download"},"download\npage"),", download ",(0,l.kt)("strong",{parentName:"p"},"Memgraph Platform")," and fire up\n",(0,l.kt)("strong",{parentName:"p"},"TGN"),". We have prepared an ",(0,l.kt)("strong",{parentName:"p"},"Amazon user-item")," dataset on which you can\nexplore link prediction using a ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/jupyter-memgraph-tutorials"},"Jupyter\nNotebook"))),(0,l.kt)("p",null,"What is ",(0,l.kt)("strong",{parentName:"p"},"not")," implemented in the module:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"node update/deletion events")," since they occur very rarely - although we\nhave prepared a codebase to easily integrate them."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"edge deletion")," events"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"time projection")," embedding calculation and ",(0,l.kt)("strong",{parentName:"li"},"identity")," embedding\ncalculation since the author mentions they perform very poorly on all datasets",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"although it is trivial to add a new layer")))),(0,l.kt)("p",null,"Feel free to open a ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage/issues"},"GitHub issue")),"\nor start a discussion on ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://discord.gg/memgraph"},"Discord"))," if you want\nto speed up development."),(0,l.kt)("p",null,"How should ",(0,l.kt)("strong",{parentName:"p"},"you")," use the following module? Prepare Cypher queries, and split\nthem into a ",(0,l.kt)("strong",{parentName:"p"},"train")," set and ",(0,l.kt)("strong",{parentName:"p"},"eval")," set. Don't forget to call the ",(0,l.kt)("inlineCode",{parentName:"p"},"set_mode"),"\nmethod. Every result is stored so that you can easily get it with the module.\nThe module reports the ",(0,l.kt)("a",{parentName:"p",href:"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html"},"mean average\nprecision"),"\nfor every batch ",(0,l.kt)("em",{parentName:"p"},"training")," or ",(0,l.kt)("em",{parentName:"p"},"evaluation")," done."),(0,l.kt)("h3",{id:"usage"},"Usage"),(0,l.kt)("p",null,"The following procedure is expected when using ",(0,l.kt)("strong",{parentName:"p"},"TGN"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"set parameters by calling ",(0,l.kt)("inlineCode",{parentName:"li"},"set_params()")," function"),(0,l.kt)("li",{parentName:"ul"},"set trigger on edge create event to call ",(0,l.kt)("inlineCode",{parentName:"li"},"update()")," function"),(0,l.kt)("li",{parentName:"ul"},"start loading your ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," queries"),(0,l.kt)("li",{parentName:"ul"},"when ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," queries are loaded, switch ",(0,l.kt)("strong",{parentName:"li"},"TGN")," mode to ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," by calling\n",(0,l.kt)("inlineCode",{parentName:"li"},"set_eval()")," function"),(0,l.kt)("li",{parentName:"ul"},"load ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," queries"),(0,l.kt)("li",{parentName:"ul"},"do a few more epochs of training and evaluation to get the best results by\ncalling ",(0,l.kt)("inlineCode",{parentName:"li"},"train_and_eval()"))),(0,l.kt)("p",null,"One thing is important to mention: by calling ",(0,l.kt)("inlineCode",{parentName:"p"},"set_eval()")," function you change\nthe mode of ",(0,l.kt)("strong",{parentName:"p"},"temporal graph networks")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"eval")," mode. Any new edges which\narrive will ",(0,l.kt)("strong",{parentName:"p"},"not")," be used to ",(0,l.kt)("inlineCode",{parentName:"p"},"train")," the module, but to ",(0,l.kt)("inlineCode",{parentName:"p"},"eval"),"."),(0,l.kt)("h3",{id:"implementation-details"},"Implementation details"),(0,l.kt)("h4",{id:"query-module"},"Query module"),(0,l.kt)("p",null,"The module is implemented using ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://pytorch.org/"},"PyTorch")),". From the\ninput (",(0,l.kt)("inlineCode",{parentName:"p"},"mgp.Edge")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"mgp.Vertex")," labels), ",(0,l.kt)("inlineCode",{parentName:"p"},"edge features")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"node features"),"\nare extracted. With a trigger set, the ",(0,l.kt)("inlineCode",{parentName:"p"},"update")," query module procedure will\nparse all new edges and extract the information the ",(0,l.kt)("strong",{parentName:"p"},"TGN")," needs to do batch by\nbatch processing."),(0,l.kt)("p",null,"On the following piece of code, ",(0,l.kt)("em",{parentName:"p"},"you")," can see what is extracted from edges while\nthe ",(0,l.kt)("strong",{parentName:"p"},"batch")," is filling up. When the current processing batch size reaches\n",(0,l.kt)("inlineCode",{parentName:"p"},"batch size")," (predefined in ",(0,l.kt)("inlineCode",{parentName:"p"},"set()"),"), we ",(0,l.kt)("strong",{parentName:"p"},"forward")," the extracted information\nto the ",(0,l.kt)("strong",{parentName:"p"},"TGN"),", which extends ",(0,l.kt)("inlineCode",{parentName:"p"},"torch.nn.Module"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@dataclasses.dataclass\nclass QueryModuleTGNBatch:\n    current_batch_size: int\n    sources: np.array\n    destinations: np.array\n    timestamps: np.array\n    edge_idxs: np.array\n    node_features: Dict[int, torch.Tensor]\n    edge_features: Dict[int, torch.Tensor]\n    batch_size: int\n    labels: np.array\n")),(0,l.kt)("h4",{id:"processing-one-batch"},"Processing one batch"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"        self._process_previous_batches()\n\n        graph_data = self._get_graph_data(\n            np.concatenate([sources.copy(), destinations.copy()], dtype=int),\n            np.concatenate([timestamps, timestamps]),\n        )\n\n        embeddings = self.tgn_net(graph_data)\n\n        ... process negative edges in a similar way\n\n        self._process_current_batch(\n            sources, destinations, node_features, edge_features, edge_idxs, timestamps\n        )\n")),(0,l.kt)("p",null,"Our ",(0,l.kt)("inlineCode",{parentName:"p"},"torch.nn.Module")," is organized as follows:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"processing previous batches - as in the ",(0,l.kt)("em",{parentName:"li"},(0,l.kt)("a",{parentName:"em",href:"https://arxiv.org/abs/2006.10637"},"research\npaper"))," this will include new computation of\nmessages collected for each node with a ",(0,l.kt)("strong",{parentName:"li"},"message function"),", aggregation of\nmessages for each node with a ",(0,l.kt)("strong",{parentName:"li"},"message aggregator")," and finally updating of\neach node's memory with a ",(0,l.kt)("strong",{parentName:"li"},"memory updater")),(0,l.kt)("li",{parentName:"ul"},"afterward, we create a computation graph used by the ",(0,l.kt)("strong",{parentName:"li"},"graph attention layer"),"\nor ",(0,l.kt)("strong",{parentName:"li"},"graph sum layer")),(0,l.kt)("li",{parentName:"ul"},"the final step includes processing the current batch, creating new\n",(0,l.kt)("strong",{parentName:"li"},"interaction")," or ",(0,l.kt)("strong",{parentName:"li"},"node events"),", and updating the ",(0,l.kt)("strong",{parentName:"li"},"raw message store"),"\nwith new ",(0,l.kt)("strong",{parentName:"li"},"events"))),(0,l.kt)("p",null,"The process repeats: as we get new edges in a batch, the batch fills, and the\nnew edges are forwarded to the ",(0,l.kt)("strong",{parentName:"p"},"TGN")," and so on."),(0,l.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"This ",(0,l.kt)("strong",{parentName:"p"},"MAGE")," module is still in its early stage. We intend to use it only for\n",(0,l.kt)("strong",{parentName:"p"},"learning")," activities. The current state of the module is that you need to\nmanually switch the TGN mode to ",(0,l.kt)("inlineCode",{parentName:"p"},"eval"),". After the switch, incoming edges will be\nused for ",(0,l.kt)("strong",{parentName:"p"},"evaluation")," only. If you wish to make it production-ready, make sure\nto either open a ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage/issues"},"GitHub issue"))," or\ndrop us a comment on ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://discord.gg/memgraph"},"Discord")),". Also, consider\nthrowing us a \u2b50 so we can continue to do even better work."))),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Trait"),(0,l.kt)("th",{parentName:"tr",align:null},"Value"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Module type")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)(c,{color:"#FB6E00",mdxType:"Highlight"},(0,l.kt)("strong",{parentName:"td"},"module")))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Implementation")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)(c,{color:"#FB6E00",mdxType:"Highlight"},(0,l.kt)("strong",{parentName:"td"},"Python")))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Graph direction")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)(c,{color:"#FB6E00",mdxType:"Highlight"},(0,l.kt)("strong",{parentName:"td"},"directed")))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Edge weights")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)(c,{color:"#FB6E00",mdxType:"Highlight"},(0,l.kt)("strong",{parentName:"td"},"weighted/unweighted")))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Parallelism")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)(c,{color:"#FB6E00",mdxType:"Highlight"},(0,l.kt)("strong",{parentName:"td"},"sequential")))))),(0,l.kt)("h2",{id:"procedures"},"Procedures"),(0,l.kt)("h3",{id:"set_paramsparams"},(0,l.kt)("inlineCode",{parentName:"h3"},"set_params(params)")),(0,l.kt)("p",null,"We have defined ",(0,l.kt)("inlineCode",{parentName:"p"},"default")," value for each of the parameters. If you wish to\nchange any of them, call the method with the defined new value."),(0,l.kt)("h4",{id:"input"},"Input:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"params: mgp.Map")," \u27a1 a dictionary containing the following parameters:")),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Type"),(0,l.kt)("th",{parentName:"tr",align:null},"Default"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"learning_type"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"self_supervised")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"self_supervised")," or ",(0,l.kt)("inlineCode",{parentName:"td"},"supervised")," depending on if you want to predict edges or node labels")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"batch_size"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"200"),(0,l.kt)("td",{parentName:"tr",align:null},"size of batch to process by TGN, recommended size ",(0,l.kt)("strong",{parentName:"td"},"200"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"num_of_layers"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"2"),(0,l.kt)("td",{parentName:"tr",align:null},"number of layers of graph neural network, ",(0,l.kt)("strong",{parentName:"td"},"2")," is the optimal size, GNNs perform worse with more layers in terms of time needed to train, but the gain in accuracy is not significant")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"layer_type"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"graph_attn")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"graph_attn")," or ",(0,l.kt)("inlineCode",{parentName:"td"},"graph_sum")," layer type as defined in the original paper")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"memory_dimension"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"100"),(0,l.kt)("td",{parentName:"tr",align:null},"dimension of memory tensor of each node")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"time_dimension"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"100"),(0,l.kt)("td",{parentName:"tr",align:null},"dimension of time vector from ",(0,l.kt)("inlineCode",{parentName:"td"},"time2vec")," paper")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"num_edge_features"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"50"),(0,l.kt)("td",{parentName:"tr",align:null},"number of edge features we will use from each edge")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"num_node_features"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"50"),(0,l.kt)("td",{parentName:"tr",align:null},"number of expected node features")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"message_dimension"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"100"),(0,l.kt)("td",{parentName:"tr",align:null},"dimension of the message, only used if you use MLP as the message function type, otherwise ignored")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"num_neighbors"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"15"),(0,l.kt)("td",{parentName:"tr",align:null},"number of sampled neighbors")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"edge_message_function_type"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"identity")),(0,l.kt)("td",{parentName:"tr",align:null},"message function type, ",(0,l.kt)("inlineCode",{parentName:"td"},"identity")," for concatenation or ",(0,l.kt)("inlineCode",{parentName:"td"},"mlp")," for projection")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"message_aggregator_type"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"last")),(0,l.kt)("td",{parentName:"tr",align:null},"message aggregator type, ",(0,l.kt)("inlineCode",{parentName:"td"},"mean")," or ",(0,l.kt)("inlineCode",{parentName:"td"},"last"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"memory_updater_type"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"gru")),(0,l.kt)("td",{parentName:"tr",align:null},"memory updater type, ",(0,l.kt)("inlineCode",{parentName:"td"},"gru")," or ",(0,l.kt)("inlineCode",{parentName:"td"},"rnn"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"num_attention_heads"),(0,l.kt)("td",{parentName:"tr",align:null},"Integer"),(0,l.kt)("td",{parentName:"tr",align:null},"1"),(0,l.kt)("td",{parentName:"tr",align:null},"number of attention heads used if you define ",(0,l.kt)("inlineCode",{parentName:"td"},"graph_attn")," as layer type")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"learning_rate"),(0,l.kt)("td",{parentName:"tr",align:null},"Float"),(0,l.kt)("td",{parentName:"tr",align:null},"1e-4"),(0,l.kt)("td",{parentName:"tr",align:null},"learning rate for ",(0,l.kt)("inlineCode",{parentName:"td"},"adam")," optimizer")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"weight_decay"),(0,l.kt)("td",{parentName:"tr",align:null},"Float"),(0,l.kt)("td",{parentName:"tr",align:null},"5e-5"),(0,l.kt)("td",{parentName:"tr",align:null},"weight decay used in ",(0,l.kt)("inlineCode",{parentName:"td"},"adam")," optimizer")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"device_type"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"cuda")),(0,l.kt)("td",{parentName:"tr",align:null},"type of device you want to use for training - ",(0,l.kt)("inlineCode",{parentName:"td"},"cuda")," or ",(0,l.kt)("inlineCode",{parentName:"td"},"cpu"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"node_features_property"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"features")),(0,l.kt)("td",{parentName:"tr",align:null},"name of features property on nodes from which we read features")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"edge_features_property"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"features")),(0,l.kt)("td",{parentName:"tr",align:null},"name of features property on edges from which we read features")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"node_label_property"),(0,l.kt)("td",{parentName:"tr",align:null},"String"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"label")),(0,l.kt)("td",{parentName:"tr",align:null},"name of label property on nodes from which we read features")))),(0,l.kt)("h4",{id:"usage-1"},"Usage:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"}," CALL tgn.set_params({learning_type:'self_supervised', batch_size:200, num_of_layers:2,\n                      layer_type:'graph_attn',memory_dimension:20, time_dimension:50,\n                      num_edge_features:20, num_node_features:20, message_dimension:100,\n                      num_neighbors:15, edge_message_function_type:'identity',\n                      message_aggregator_type:'last', memory_updater_type:'gru', num_attention_heads:1});\n")),(0,l.kt)("h3",{id:"updateedges"},(0,l.kt)("inlineCode",{parentName:"h3"},"update(edges)")),(0,l.kt)("p",null,"This function scrapes data from edges, including ",(0,l.kt)("inlineCode",{parentName:"p"},"edge_features")," and\n",(0,l.kt)("inlineCode",{parentName:"p"},"node_features")," if they exist, and fills up the batch. If the batch is ready the\n",(0,l.kt)("strong",{parentName:"p"},"TGN")," will process it and be ready to accept new incoming edges."),(0,l.kt)("h4",{id:"input-1"},"Input:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"edges: mgp.List[mgp.Edges]")," \u27a1 List of edges to preprocess (that arrive in a\nstream to Memgraph). If a batch is full, ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," starts, depending\non the mode.")),(0,l.kt)("h4",{id:"usage-2"},"Usage:"),(0,l.kt)("p",null,"There are a few options here:"),(0,l.kt)("p",null,"The most convenient one is to create a\n",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"https://memgraph.com/docs/memgraph/reference-guide/triggers"},"trigger"))," so\nthat every time an edge is added to the graph, the trigger calls the procedure\nand makes an update."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE TRIGGER create_embeddings ON --\x3e CREATE BEFORE COMMIT\nEXECUTE CALL tgn.update(createdEdges) RETURN 1;\n")),(0,l.kt)("p",null,"The second option is to add all the edges and then call the algorithm with them:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"MATCH (n)-[e]->(m)\nWITH COLLECT(e) as edges\nCALL tgn.update(edges) RETURN 1;\n")),(0,l.kt)("h3",{id:"get"},(0,l.kt)("inlineCode",{parentName:"h3"},"get()")),(0,l.kt)("p",null,"Get calculated embeddings for each vertex."),(0,l.kt)("h4",{id:"output"},"Output:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"node: mgp.Vertex")," \u27a1 Vertex (node) in Memgraph."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"embedding: mgp.List[float]")," \u27a1 Low-dimensional representation of node in form\nof graph embedding.")),(0,l.kt)("h4",{id:"usage-3"},"Usage:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.get() YIELD * RETURN *;\n")),(0,l.kt)("h3",{id:"set_eval"},(0,l.kt)("inlineCode",{parentName:"h3"},"set_eval()")),(0,l.kt)("p",null,"Change ",(0,l.kt)("strong",{parentName:"p"},"TGN")," mode to ",(0,l.kt)("inlineCode",{parentName:"p"},"eval"),"."),(0,l.kt)("h4",{id:"usage-4"},"Usage:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.set_eval() YIELD *;\n")),(0,l.kt)("h3",{id:"get_results"},(0,l.kt)("inlineCode",{parentName:"h3"},"get_results()")),(0,l.kt)("p",null,"This method will return ",(0,l.kt)("inlineCode",{parentName:"p"},"results")," for every batch you did ",(0,l.kt)("inlineCode",{parentName:"p"},"train")," or ",(0,l.kt)("inlineCode",{parentName:"p"},"eval")," on,\nas well as ",(0,l.kt)("inlineCode",{parentName:"p"},"average_precision"),", and ",(0,l.kt)("inlineCode",{parentName:"p"},"batch_process_time"),". Epoch count starts\nfrom 1."),(0,l.kt)("h4",{id:"output-1"},"Output:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"epoch_num:mgp.Number")," \u27a1 The number of ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," epochs."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_num:mgp.Number")," \u27a1 The number of batches per ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," epoch."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_process_time:mgp.Number")," \u27a1 Time needed to process a batch."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"average_precision:mgp.Number")," \u27a1 Mean average precision on the current batch."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_type:string")," \u27a1 A string indicating whether ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," is performed\non the batch.")),(0,l.kt)("h4",{id:"usage-5"},"Usage:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.get_results() YIELD * RETURN *;\n")),(0,l.kt)("h3",{id:"train_and_evalnum_epochs"},(0,l.kt)("inlineCode",{parentName:"h3"},"train_and_eval(num_epochs)")),(0,l.kt)("p",null,"The purpose of this method is to do additional training rounds on ",(0,l.kt)("inlineCode",{parentName:"p"},"train")," edges\nand ",(0,l.kt)("inlineCode",{parentName:"p"},"eval")," on evaluation edges."),(0,l.kt)("h4",{id:"input-2"},"Input:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"num_epochs: integer")," \u27a1 Perform additional epoch training and evaluation ",(0,l.kt)("strong",{parentName:"li"},"after"),"\nthe stream is done.")),(0,l.kt)("h4",{id:"output-2"},"Output:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"epoch_num: integer")," \u27a1 The epoch of the batch for which performance statistics\nwill be returned."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_num: integer")," \u27a1 The number of the batch for which performance statistics\nwill be returned."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_process_time: float")," \u27a1 Processing time in seconds for a batch."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"average_precision:mgp.Number")," \u27a1 Mean average precision on the current batch."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_type:string")," \u27a1 Whether we performed ",(0,l.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"eval")," on the batch.")),(0,l.kt)("h4",{id:"usage-6"},"Usage:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.train_and_eval(10) YIELD * RETURN *;\n")),(0,l.kt)("h3",{id:"predict_link_scorevertex_1-vertex_2"},(0,l.kt)("inlineCode",{parentName:"h3"},"predict_link_score(vertex_1, vertex_2)")),(0,l.kt)("p",null,"The purpose of this method is to get the link prediction score for two vertices in graph if you have been\ntraining ",(0,l.kt)("inlineCode",{parentName:"p"},"TGN")," for the link prediction task."),(0,l.kt)("h4",{id:"input-3"},"Input:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"src: mgp.Vertex")," \u27a1 Source vertex of the link prediction"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"dest: mgp.Vertex")," \u27a1 Destination vertex of the link prediction")),(0,l.kt)("h4",{id:"output-3"},"Output:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"prediction: mgp.Number")," \u27a1 Float number between 0 and 1, likelihood of link between ",(0,l.kt)("inlineCode",{parentName:"li"},"source")," vertex and ",(0,l.kt)("inlineCode",{parentName:"li"},"destination"),"\nvertex.")),(0,l.kt)("h4",{id:"usage-7"},"Usage:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"MATCH (n:User)\nWITH n\nLIMIT 1\nMATCH (m:Item)\nOPTIONAL MATCH  (n)-[r]->(m)\n  WHERE r is null\nCALL tgn.predict_link_score(n,m) YIELD *\nRETURN n,m, prediction;\n")),(0,l.kt)("h2",{id:"example"},"Example"),(0,l.kt)(i.Z,{groupId:"example",defaultValue:"visualization",values:[{label:"Step 1: Input graph",value:"visualization"},{label:"Step 2: Set parameters",value:"cypher-param-set"},{label:"Step 3: Set trigger",value:"cypher-trigger-set"},{label:"Step 4: Load training batch",value:"cypher-train-load"},{label:"Step 5: Change mode",value:"cypher-mode-change"},{label:"Step 6: Load evaluation batch",value:"cypher-eval-load"},{label:"Step 7: Train epochs",value:"cypher-epoch-train"},{label:"Step 8: Run",value:"run"},{label:"Step 9: Results",value:"result"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"visualization",mdxType:"TabItem"},(0,l.kt)("img",{src:n(59871).Z})),(0,l.kt)(o.Z,{value:"cypher-param-set",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.set_params({learning_type:'self_supervised', batch_size:2, num_of_layers:1,\n                      layer_type:'graph_attn',memory_dimension:100, time_dimension:100,\n                      num_edge_features:20, num_node_features:20, message_dimension:100,\n                      num_neighbors:10, edge_message_function_type:'identity',\n                      message_aggregator_type:'last', memory_updater_type:'gru', num_attention_heads:1});\n"))),(0,l.kt)(o.Z,{value:"cypher-trigger-set",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE TRIGGER create_embeddings ON --\x3e CREATE BEFORE COMMIT\nEXECUTE CALL tgn.update(createdEdges) RETURN 1;\n"))),(0,l.kt)(o.Z,{value:"cypher-train-load",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"MERGE (n:Node {id: 1}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 2}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 10}) MERGE (m:Node {id: 5}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 5}) MERGE (m:Node {id: 2}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 9}) MERGE (m:Node {id: 7}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 7}) MERGE (m:Node {id: 3}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 3}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 9}) MERGE (m:Node {id: 8}) CREATE (n)-[:RELATION]->(m);\n"))),(0,l.kt)(o.Z,{value:"cypher-mode-change",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.set_eval() YIELD *;\n\n"))),(0,l.kt)(o.Z,{value:"cypher-eval-load",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"},"MERGE (n:Node {id: 8}) MERGE (m:Node {id: 4}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 4}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\n"))),(0,l.kt)(o.Z,{value:"cypher-epoch-train",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"}," CALL tgn.train_and_eval(5) YIELD *\n"))),(0,l.kt)(o.Z,{value:"run",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-cypher"}," CALL tgn.get_results() YIELD  epoch_num, batch_num, average_precision, batch_process_time, batch_type\n RETURN epoch_num, batch_num, average_precision, batch_type, batch_process_time;\n"))),(0,l.kt)(o.Z,{value:"result",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-plaintext"},'+--------------------+--------------------+--------------------+--------------------+--------------------+\n| epoch_num          | batch_num          | average_precision  | batch_type         | batch_process_time |\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n| 1                  | 1                  | 0.5                | "Train"            | 0.05               |\n| 1                  | 2                  | 0.42               | "Eval"             | 0.02               |\n| 2                  | 1                  | 0.83               | "Train"            | 0.03               |\n| 2                  | 2                  | 0.5                | "Train"            | 0.04               |\n| 2                  | 3                  | 0.5                | "Train"            | 0.04               |\n| 2                  | 4                  | 0.58               | "Train"            | 0.04               |\n| 2                  | 5                  | 0.83               | "Eval"             | 0.02               |\n| 3                  | 1                  | 0.5                | "Train"            | 0.03               |\n| 3                  | 2                  | 0.75               | "Train"            | 0.03               |\n| 3                  | 3                  | 0.83               | "Train"            | 0.03               |\n| 3                  | 4                  | 1                  | "Train"            | 0.04               |\n| 3                  | 5                  | 0.83               | "Eval"             | 0.02               |\n| 4                  | 1                  | 0.5                | "Train"            | 0.03               |\n| 4                  | 2                  | 0.58               | "Train"            | 0.03               |\n| 4                  | 3                  | 1                  | "Train"            | 0.03               |\n| 4                  | 4                  | 1                  | "Train"            | 0.04               |\n| 4                  | 5                  | 1                  | "Eval"             | 0.02               |\n| 5                  | 1                  | 0.83               | "Train"            | 0.03               |\n| 5                  | 2                  | 0.58               | "Train"            | 0.03               |\n| 5                  | 3                  | 1                  | "Train"            | 0.03               |\n| 5                  | 4                  | 1                  | "Train"            | 0.03               |\n| 5                  | 5                  | 0.83               | "Eval"             | 0.02               |\n| 6                  | 1                  | 0.58               | "Train"            | 0.03               |\n| 6                  | 2                  | 0.83               | "Train"            | 0.03               |\n| 6                  | 3                  | 1                  | "Train"            | 0.03               |\n| 6                  | 4                  | 1                  | "Train"            | 0.03               |\n| 6                  | 5                  | 1                  | "Eval"             | 0.01               |\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n')))))}h.isMDXComponent=!0},58215:function(e,t,n){n.d(t,{Z:function(){return r}});var a=n(67294);function r(e){var t=e.children,n=e.hidden,r=e.className;return a.createElement("div",{role:"tabpanel",hidden:n,className:r},t)}},9877:function(e,t,n){n.d(t,{Z:function(){return m}});var a=n(87462),r=n(67294),l=n(72389),i=n(5979),o=n(86010),p="tabItem_LplD";function s(e){var t,n,l,s=e.lazy,m=e.block,d=e.defaultValue,u=e.values,g=e.groupId,c=e.className,k=r.Children.map(e.children,(function(e){if((0,r.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),h=null!=u?u:k.map((function(e){var t=e.props;return{value:t.value,label:t.label,attributes:t.attributes}})),N=(0,i.lx)(h,(function(e,t){return e.value===t.value}));if(N.length>0)throw new Error('Docusaurus error: Duplicate values "'+N.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var f=null===d?d:null!=(t=null!=d?d:null==(n=k.find((function(e){return e.props.default})))?void 0:n.props.value)?t:null==(l=k[0])?void 0:l.props.value;if(null!==f&&!h.some((function(e){return e.value===f})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+f+'" but none of its children has the corresponding value. Available values are: '+h.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var y=(0,i.UB)(),v=y.tabGroupChoices,b=y.setTabGroupChoices,_=(0,r.useState)(f),w=_[0],T=_[1],E=[],C=(0,i.o5)().blockElementScrollPositionUntilNextRender;if(null!=g){var x=v[g];null!=x&&x!==w&&h.some((function(e){return e.value===x}))&&T(x)}var R=function(e){var t=e.currentTarget,n=E.indexOf(t),a=h[n].value;a!==w&&(C(t),T(a),null!=g&&b(g,a))},I=function(e){var t,n=null;switch(e.key){case"ArrowRight":var a=E.indexOf(e.currentTarget)+1;n=E[a]||E[0];break;case"ArrowLeft":var r=E.indexOf(e.currentTarget)-1;n=E[r]||E[E.length-1]}null==(t=n)||t.focus()};return r.createElement("div",{className:"tabs-container"},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":m},c)},h.map((function(e){var t=e.value,n=e.label,l=e.attributes;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:w===t?0:-1,"aria-selected":w===t,key:t,ref:function(e){return E.push(e)},onKeyDown:I,onFocus:R,onClick:R},l,{className:(0,o.Z)("tabs__item",p,null==l?void 0:l.className,{"tabs__item--active":w===t})}),null!=n?n:t)}))),s?(0,r.cloneElement)(k.filter((function(e){return e.props.value===w}))[0],{className:"margin-vert--md"}):r.createElement("div",{className:"margin-vert--md"},k.map((function(e,t){return(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==w})}))))}function m(e){var t=(0,l.Z)();return r.createElement(s,(0,a.Z)({key:String(t)},e))}},59871:function(e,t,n){t.Z=n.p+"assets/images/graph_visualization-387a6a6a1fbd6a6872f7f727ee3706d8.png"}}]);
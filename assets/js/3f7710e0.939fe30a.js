"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[46181],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),m=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=m(e.components);return r.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=m(n),d=a,h=u["".concat(s,".").concat(d)]||u[d]||c[d]||o;return n?r.createElement(h,l(l({ref:t},p),{},{components:n})):r.createElement(h,l({ref:t},p))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,l=new Array(o);l[0]=u;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:a,l[1]=i;for(var m=2;m<o;m++)l[m]=n[m];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},4995:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return i},metadata:function(){return m},toc:function(){return c}});var r=n(87462),a=n(63366),o=(n(67294),n(3905)),l=["components"],i={id:"custom-file-system-importer",title:"How to make a custom file system importer",sidebar_label:"Make a custom file system importer"},s=void 0,m={unversionedId:"how-to-guides/loaders/custom-file-system-importer",id:"how-to-guides/loaders/custom-file-system-importer",title:"How to make a custom file system importer",description:"To learn how to import table data from a file to the Memgraph database, head",source:"@site/gqlalchemy/how-to-guides/loaders/make-a-custom-file-system-importer.md",sourceDirName:"how-to-guides/loaders",slug:"/how-to-guides/loaders/custom-file-system-importer",permalink:"/docs/gqlalchemy/how-to-guides/loaders/custom-file-system-importer",editUrl:"https://github.com/memgraph/docs/tree/master/gqlalchemy/how-to-guides/loaders/make-a-custom-file-system-importer.md",tags:[],version:"current",frontMatter:{id:"custom-file-system-importer",title:"How to make a custom file system importer",sidebar_label:"Make a custom file system importer"},sidebar:"gqlalchemy",previous:{title:"Import table data as a graph",permalink:"/docs/gqlalchemy/how-to-guides/loaders/table-to-graph-importer"},next:{title:"Manage Memgraph Docker instances",permalink:"/docs/gqlalchemy/how-to-guides/memgraph-docker-instance"}},p={},c=[{value:"Implementing a new <code>FileSystemHandler</code>",id:"implementing-a-new-filesystemhandler",level:2},{value:"1. Extend the <code>FileSystemHandler</code> class",id:"1-extend-the-filesystemhandler-class",level:3},{value:"2. Wrap the <code>TableToGraphImporter</code>",id:"2-wrap-the-tabletographimporter",level:3},{value:"3. Call <code>translate()</code>",id:"3-call-translate",level:3}],u={toc:c};function d(e){var t=e.components,n=(0,a.Z)(e,l);return(0,o.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"To learn how to import table data from a file to the Memgraph database, head\nover to the ",(0,o.kt)("a",{parentName:"p",href:"/docs/gqlalchemy/how-to-guides/loaders/table-to-graph-importer"},"How to import table\ndata")," guide.")),(0,o.kt)("p",null,"If you want to read from a file system not currently supported by\n",(0,o.kt)("strong",{parentName:"p"},"GQLAlchemy"),", or use a file type currently not readable, you can implement\nyour own by extending abstract classes ",(0,o.kt)("inlineCode",{parentName:"p"},"FileSystemHandler")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"DataLoader"),",\nrespectively."),(0,o.kt)("h2",{id:"implementing-a-new-filesystemhandler"},"Implementing a new ",(0,o.kt)("inlineCode",{parentName:"h2"},"FileSystemHandler")),(0,o.kt)("p",null,"For this guide, you will use the existing ",(0,o.kt)("inlineCode",{parentName:"p"},"PyArrowDataLoader")," capable of reading\nCSV, Parquet, ORC and IPC/Feather/Arrow file formats. The PyArrow loader class\nsupports ",(0,o.kt)("a",{parentName:"p",href:"https://filesystem-spec.readthedocs.io/en/latest/"},"fsspec"),"-compatible\nfile systems, so to implement an ",(0,o.kt)("strong",{parentName:"p"},"Azure Blob")," file system, you need to follow\nthese steps."),(0,o.kt)("h3",{id:"1-extend-the-filesystemhandler-class"},"1. Extend the ",(0,o.kt)("inlineCode",{parentName:"h3"},"FileSystemHandler")," class"),(0,o.kt)("p",null,"This class holds the connection to the file system service and handles the path\nfrom which the ",(0,o.kt)("inlineCode",{parentName:"p"},"DataLoader")," object reads files. To get a fsspec-compatible instance of\nan Azure Blob connection, you can use the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/fsspec/adlfs"},"adlfs")," package. We are going to pass ",(0,o.kt)("inlineCode",{parentName:"p"},"adlfs"),"-specific parameters such as ",(0,o.kt)("inlineCode",{parentName:"p"},"blob_account_name")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"blob_account_key")," via kwargs. All that's left to do\nis to override the ",(0,o.kt)("inlineCode",{parentName:"p"},"get_path")," method."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import adlfs\n\nclass AzureBlobFileSystemHandler(FileSystemHandler):\n\n    def __init__(self, container_name: str, **kwargs) -> None:\n        """Initializes connection and data container."""\n        super().__init__(fs=adlfs.AzureBlobFileSystem(**kwargs))\n        self._container_name = container_name\n\n    def get_path(self, collection_name: str) -> str:\n        """Get file path in file system."""\n        return f"{self._container_name}/{collection_name}"\n')),(0,o.kt)("h3",{id:"2-wrap-the-tabletographimporter"},"2. Wrap the ",(0,o.kt)("inlineCode",{parentName:"h3"},"TableToGraphImporter")),(0,o.kt)("p",null,"Next, you are going to wrap the ",(0,o.kt)("inlineCode",{parentName:"p"},"TableToGraphImporter")," class. This is optional since you can use the class directly, but it will be easier to use if we extend it with our custom importer class. Since we will be using PyArrow for data loading, you can extend the ",(0,o.kt)("inlineCode",{parentName:"p"},"PyArrowImporter")," class (which extends the ",(0,o.kt)("inlineCode",{parentName:"p"},"TableToGraphImporter"),") and make your own\n",(0,o.kt)("inlineCode",{parentName:"p"},"PyArrowAzureBlobImporter"),". This class should initialize the ",(0,o.kt)("inlineCode",{parentName:"p"},"AzureBlobFileSystemHandler")," and leave the rest to the ",(0,o.kt)("inlineCode",{parentName:"p"},"PyArrowImporter")," class. It should also receive a ",(0,o.kt)("inlineCode",{parentName:"p"},"file_extension_enum")," argument, which defines the file type that you are going to be reading."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'class PyArrowAzureBlobImporter(PyArrowImporter):\n    """PyArrowImporter wrapper for use with Azure Blob File System."""\n\n    def __init__(\n        self,\n        container_name: str,\n        file_extension_enum: PyArrowFileTypeEnum,\n        data_configuration: Dict[str, Any],\n        memgraph: Optional[Memgraph] = None,\n        **kwargs,\n    ) -> None:\n        super().__init__(\n            file_system_handler=AzureBlobFileSystemHandler(        \n                container_name=container_name, **kwargs\n            ),\n            file_extension_enum=file_extension_enum,\n            data_configuration=data_configuration,\n            memgraph=memgraph,\n        )\n')),(0,o.kt)("h3",{id:"3-call-translate"},"3. Call ",(0,o.kt)("inlineCode",{parentName:"h3"},"translate()")),(0,o.kt)("p",null,"Finally, to use your custom file system, initialize the Importer class and call\n",(0,o.kt)("inlineCode",{parentName:"p"},"translate()")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'importer = PyArrowAzureBlobImporter(\n    container_name="test"\n    file_extension_enum=PyArrowFileTypeEnum.Parquet,\n    data_configuration=parsed_yaml,\n    blob_account_name="your_account_name",\n    blob_account_key="your_account_key",\n)\n\nimporter.translate(drop_database_on_start=True)\n')),(0,o.kt)("p",null,"If you want to see the full implementation of the ",(0,o.kt)("inlineCode",{parentName:"p"},"AzureBlobFileSystem")," and\nother loader components, have a look ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/memgraph/gqlalchemy"},"at the\ncode"),". Feel free to create a PR on the\nGQLAlchemy repository if you think of a new feature we could use. If you have\nany more questions, join our community and ping us on\n",(0,o.kt)("a",{parentName:"p",href:"https://discord.gg/memgraph"},"Discord"),"."))}d.isMDXComponent=!0}}]);
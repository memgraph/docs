"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[88143],{3905:(e,t,a)=>{a.d(t,{Zo:()=>l,kt:()=>d});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var m=n.createContext({}),p=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},l=function(e){var t=p(e.components);return n.createElement(m.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,m=e.parentName,l=i(e,["components","mdxType","originalType","parentName"]),u=p(a),d=r,h=u["".concat(m,".").concat(d)]||u[d]||c[d]||s;return a?n.createElement(h,o(o({ref:t},l),{},{components:a})):n.createElement(h,o({ref:t},l))}));function d(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=u;var i={};for(var m in t)hasOwnProperty.call(t,m)&&(i[m]=t[m]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var p=2;p<s;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},38687:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>i,toc:()=>p});var n=a(87462),r=(a(67294),a(3905));const s={id:"kafka-streams",title:"How to manage Kafka streams",sidebar_label:"Manage Kafka streams"},o=void 0,i={unversionedId:"how-to-guides/streams/kafka/kafka-streams",id:"version-2.2.1/how-to-guides/streams/kafka/kafka-streams",title:"How to manage Kafka streams",description:"If you are not familiar with Kafka, then please check out their [quickstart",source:"@site/memgraph_versioned_docs/version-2.2.1/how-to-guides/streams/kafka/kafka-streams.md",sourceDirName:"how-to-guides/streams/kafka",slug:"/how-to-guides/streams/kafka/kafka-streams",permalink:"/docs/memgraph/2.2.1/how-to-guides/streams/kafka/kafka-streams",draft:!1,editUrl:"https://github.com/memgraph/docs/tree/master/memgraph_versioned_docs/version-2.2.1/how-to-guides/streams/kafka/kafka-streams.md",tags:[],version:"2.2.1",frontMatter:{id:"kafka-streams",title:"How to manage Kafka streams",sidebar_label:"Manage Kafka streams"},sidebar:"memgraph",previous:{title:"Create a backup",permalink:"/docs/memgraph/2.2.1/how-to-guides/create-backup"},next:{title:"Implement transformation modules",permalink:"/docs/memgraph/2.2.1/how-to-guides/streams/kafka/implement-transformation-module"}},m={},p=[{value:"Configuring Memgraph",id:"configuring-memgraph",level:2},{value:"Creating the stream",id:"creating-the-stream",level:2},{value:"Check if the stream is working",id:"check-if-the-stream-is-working",level:2},{value:"Start the stream",id:"start-the-stream",level:2},{value:"Committed offsets",id:"committed-offsets",level:2}],l={toc:p};function c(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},l,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"If you are not familiar with Kafka, then please check out their ",(0,r.kt)("a",{parentName:"p",href:"https://kafka.apache.org/quickstart"},"quickstart\nguide")," to get familiar. In the\ndocumentation, we assume that a Kafka server is available on the 9092 port of\nthe local machine (",(0,r.kt)("inlineCode",{parentName:"p"},"localhost:9092"),") as the default configuration of the Kafka\nquick start guide. Please adjust your setup accordingly."),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Check out the ",(0,r.kt)("strong",{parentName:"p"},"example-streaming-app")," on\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/memgraph/example-streaming-app"},"GitHub")," to see how Memgraph\ncan be connected to a Kafka stream.")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"For detailed technical information on streaming support, check out the\n",(0,r.kt)("a",{parentName:"p",href:"/docs/memgraph/2.2.1/reference-guide/streams"},"reference guide"),".")),(0,r.kt)("h2",{id:"configuring-memgraph"},"Configuring Memgraph"),(0,r.kt)("p",null,"The list of default bootstrap servers can be set by the\n",(0,r.kt)("inlineCode",{parentName:"p"},"--kafka-bootstrap-servers")," configuration option. It has to be set explicitly.\nMorever, the user can overwrite the default list of brokers passed to\n",(0,r.kt)("inlineCode",{parentName:"p"},"--kafka-bootstrap-servers")," by setting the ",(0,r.kt)("inlineCode",{parentName:"p"},"BOOTSTRAP_SERVERS <brokers>")," option\non a ",(0,r.kt)("inlineCode",{parentName:"p"},"CREATE KAFKA STREAM")," clause."),(0,r.kt)("h2",{id:"creating-the-stream"},"Creating the stream"),(0,r.kt)("p",null,"The very first step is to make sure at least one transformation module is loaded\ninto Memgraph. If you are not sure how to define them, check out the\n",(0,r.kt)("a",{parentName:"p",href:"/docs/memgraph/2.2.1/how-to-guides/streams/kafka/implement-transformation-module"},"transformation module\nguide"),".\nWe are going to use ",(0,r.kt)("inlineCode",{parentName:"p"},"transformation.my_transformation")," from that example, but we\nare going to alias it as ",(0,r.kt)("inlineCode",{parentName:"p"},"my.transform")," to make the size of result tables\nslimmer. For the topic name, we are going to use the topic from the Kafka quick\nstart, ",(0,r.kt)("inlineCode",{parentName:"p"},"quickstart-events"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE KAFKA STREAM myStream\nTOPICS quickstart-events\nTRANSFORM my.transform;\n")),(0,r.kt)("p",null,"Check the created stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"SHOW STREAMS;\n")),(0,r.kt)("p",null,"The result should be similar to:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},'+----------------------+----------------------+---------------------+---------------------+----------------------+----------------------+----------------------+\n| name                 | type                 | batch_interval      | batch_size          | transformation_name  | owner                | is running           |\n+----------------------+----------------------+---------------------+---------------------+----------------------+----------------------+----------------------+\n| "myStream"           | "kafka"              | 100                 | 1000                | "my.kafka_transform" | Null                 | false                |\n+----------------------+----------------------+---------------------+---------------------+----------------------+----------------------+----------------------+\n')),(0,r.kt)("p",null,"The result contains the most important information about the existing streams,\ne.g., its name, topics it is subscribed to, etc."),(0,r.kt)("h2",{id:"check-if-the-stream-is-working"},"Check if the stream is working"),(0,r.kt)("p",null,"Maybe at first, you don't want to run the stream in the background but see the\nactual result of the transformation. This can be handy when implementing a\ntransformation. To achieve that, we can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"CHECK STREAM")," query. This query\nwill consume the message from the last committed offset but won't commit the\noffsets. That means you are free to play around with it, and there won't be any\npermanent effects. For a freshly created stream there is probably no committed offset, so the ",(0,r.kt)("inlineCode",{parentName:"p"},"CHECK STREAM")," query will wait for new messages. By default, the\nquery will wait ",(0,r.kt)("inlineCode",{parentName:"p"},"30000")," milliseconds (",(0,r.kt)("inlineCode",{parentName:"p"},"30")," seconds) and after that, it will\nthrow a timeout exception. To give us some more time, use a larger timeout,\ne.g.: ",(0,r.kt)("inlineCode",{parentName:"p"},"60000")," milliseconds (",(0,r.kt)("inlineCode",{parentName:"p"},"60")," seconds):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CHECK STREAM myStream TIMEOUT 60000;\n")),(0,r.kt)("p",null,"If you started the query, let's send some messages to the topic in the same way\nas described in the Kafka quick start guide. You should see a similar output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},'+--------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n| query                                                                                | parameters                                                                           |\n+--------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})"       | {payload: "Example message 1", timestamp: 1625757014009, topic: "quickstart-events"} |\n+--------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n')),(0,r.kt)("p",null,"If you want to consume more batches, you can also increase the batch limit:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CHECK STREAM myStream BATCH_LIMIT 3 TIMEOUT 60000;\n")),(0,r.kt)("p",null,"As a result, you should see multiple messages (probably 3) in the output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},'+--------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n| query                                                                                | parameters                                                                           |\n+--------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})"       | {payload: "Memgraph <3 Kafka", timestamp: 1625757026942, topic: "quickstart-events"} |\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})"       | {payload: "Example message 2", timestamp: 1625757112493, topic: "quickstart-events"} |\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})"       | {payload: "Example message 3", timestamp: 1625757118408, topic: "quickstart-events"} |\n+--------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n')),(0,r.kt)("h2",{id:"start-the-stream"},"Start the stream"),(0,r.kt)("p",null,"As we just demonstrated that the stream is working, we can start to ingest data\ninto the database by starting the stream and sending some messages to the topic."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"START STREAM myStream;\n")),(0,r.kt)("p",null,"After sending a few messages to the topic, the created vertices can be checked\nby executing ",(0,r.kt)("inlineCode",{parentName:"p"},"MATCH (n: MESSAGE) RETURN n"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},'+-----------------------------------------------------------------------------------------------+\n| n                                                                                             |\n+-----------------------------------------------------------------------------------------------+\n| (:MESSAGE {payload: "first message", timestamp: 1625757438919, topic: "quickstart-events"})   |\n| (:MESSAGE {payload: "another message", timestamp: 1625757441665, topic: "quickstart-events"}) |\n| (:MESSAGE {payload: "it is working!", timestamp: 1625757444175, topic: "quickstart-events"})  |\n+-----------------------------------------------------------------------------------------------+\n')),(0,r.kt)("h2",{id:"committed-offsets"},"Committed offsets"),(0,r.kt)("p",null,"As our stream processed at least one message after starting it, it will commit\nthe message offset to the Kafka cluster. That means if the stream is stopped\nby stopping it with the ",(0,r.kt)("inlineCode",{parentName:"p"},"STOP STREAM myStream")," query (or by shutting Memgraph\ndown), the last committed offset will be retrieved from the Kafka cluster after\nrestarting the stream."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"NOTE: As the committed offsets are stored for the consumer groups on the Kafka\ncluster, if a new stream is created using the same consumer group, it might\ncontinue consuming the message from the same offset where the previous stream\nstopped. You can mitigate this by using different consumer group names or\nresetting the committed offset via Kafka admin client.")),(0,r.kt)("p",null,"Previously, we mentioned that the ",(0,r.kt)("inlineCode",{parentName:"p"},"CHECK STREAM")," query doesn't modify the\ncommitted offsets, which means using ",(0,r.kt)("inlineCode",{parentName:"p"},"CHECK STREAM")," on a stream that already\nhas some offsets committed can result in executing the transformation on the\nsame message multiple times. To demonstrate that, first, let's stop the stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"STOP STREAM myStream;\n")),(0,r.kt)("p",null,"And then send a few messages to the topic, e.g.: ",(0,r.kt)("inlineCode",{parentName:"p"},"message A"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"message B")," and\n",(0,r.kt)("inlineCode",{parentName:"p"},"message C"),". Then run the same query as before:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CHECK STREAM myStream TIMEOUT 60000;\n")),(0,r.kt)("p",null,"Running this query multiple times should emit the same results:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},'+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n| query                                                                          | parameters                                                                     |\n+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})" | {payload: "message A", timestamp: 1625758319964, topic: "quickstart-events"}   |\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})" | {payload: "message B", timestamp: 1625758321735, topic: "quickstart-events"}   |\n| "CREATE (n:MESSAGE {timestamp: $timestamp, payload: $payload, topic: $topic})" | {payload: "message C", timestamp: 1625758323795, topic: "quickstart-events"}   |\n+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n')))}c.isMDXComponent=!0}}]);
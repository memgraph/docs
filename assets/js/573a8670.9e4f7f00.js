"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[17250],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>g});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},d=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),m=p(n),g=r,c=m["".concat(s,".").concat(g)]||m[g]||u[g]||i;return n?a.createElement(c,l(l({ref:t},d),{},{components:n})):a.createElement(c,l({ref:t},d))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,l=new Array(i);l[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,l[1]=o;for(var p=2;p<i;p++)l[p]=n[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},35824:(e,t,n)=>{n.r(t),n.d(t,{Highlight:()=>g,assets:()=>u,contentTitle:()=>p,default:()=>k,frontMatter:()=>s,metadata:()=>d,toc:()=>m});var a=n(87462),r=(n(67294),n(3905)),i=n(74866),l=n(85162),o=n(83523);const s={id:"link-prediction-with-gnn",title:"link_prediction_with_gnn",sidebar_label:"link_prediction_with_gnn"},p=void 0,d={unversionedId:"query-modules/python/link-prediction-with-gnn",id:"query-modules/python/link-prediction-with-gnn",title:"link_prediction_with_gnn",description:"Link prediction can be defined as a problem where one wants to predict if there is a link between two nodes in the graph. It can be used for predicting missing or future links in the evolving graph. Using the notation G = (V, E) for a graph with nodes V and edges E and given two nodes v1 and v2, the link prediction algorithm tries to predict whether those two nodes will be connected, based on the node features and graph structure. Lately, graph neural networks have been often used for node-classification and link-prediction problems. They are extremely useful in numerous interdisciplinary fields of work where is important to incorporate domain-specific knowledge to capture more fine-grained relationships among the data. Such fields usually involve working with heterogeneous and large-scale graphs. GNNs iteratively update node representations by aggregating the representations of node neighbors and their representation from the previous iteration. Such properties make graph neural networks a great tool for various problems we in Memgraph encounter. If your graph is evolving in time, check TGN model that Memgraph engineers have already developed.",source:"@site/mage/query-modules/python/gnn-link-prediction.md",sourceDirName:"query-modules/python",slug:"/query-modules/python/link-prediction-with-gnn",permalink:"/docs/mage/query-modules/python/link-prediction-with-gnn",draft:!1,editUrl:"https://github.com/memgraph/docs/tree/master/mage/query-modules/python/gnn-link-prediction.md",tags:[],version:"current",frontMatter:{id:"link-prediction-with-gnn",title:"link_prediction_with_gnn",sidebar_label:"link_prediction_with_gnn"},sidebar:"mage",previous:{title:"label",permalink:"/docs/mage/query-modules/cpp/label"},next:{title:"llm_util",permalink:"/docs/mage/query-modules/python/llm-util"}},u={},m=[{value:"Blog Posts",id:"blog-posts",level:3},{value:"About the query module",id:"about-the-query-module",level:3},{value:"Usage",id:"usage",level:3},{value:"Implementation details",id:"implementation-details",level:3},{value:"<strong>Splitting the dataset</strong>",id:"splitting-the-dataset",level:4},{value:"<strong>Self-loops</strong>",id:"self-loops",level:4},{value:"<strong>Batch training</strong>",id:"batch-training",level:4},{value:"Procedures",id:"procedures",level:2},{value:"<code>set_model_parameters()</code>",id:"set_model_parameters",level:3},{value:"<strong>Input</strong>:",id:"input",level:4},{value:"<strong>Output</strong>:",id:"output",level:4},{value:"<code>train()</code>",id:"train",level:3},{value:"<strong>Output</strong>:",id:"output-1",level:4},{value:"<code>get_training_results()</code>",id:"get_training_results",level:3},{value:"<strong>Output:</strong>",id:"output-2",level:4},{value:"<code>predict()</code>",id:"predict",level:3},{value:"Input",id:"input-1",level:4},{value:"Output",id:"output-3",level:4},{value:"<code>recommend()</code>",id:"recommend",level:3},{value:"Input",id:"input-2",level:4},{value:"Output",id:"output-4",level:4},{value:"<code>load_context()</code>",id:"load_context",level:3},{value:"Input",id:"input-3",level:4},{value:"Output",id:"output-5",level:4},{value:"<code>reset_parameters()</code>",id:"reset_parameters",level:3},{value:"Output",id:"output-6",level:4},{value:"Results",id:"results",level:2},{value:"Example",id:"example",level:2},{value:"FAQ",id:"faq",level:2},{value:"<strong>Why can I get into problems with reverse edges?</strong>",id:"why-can-i-get-into-problems-with-reverse-edges",level:3},{value:"<strong>What is a transductive dataset split?</strong>",id:"what-is-a-transductive-dataset-split",level:3}],g=e=>{let{children:t,color:n}=e;return(0,r.kt)("span",{style:{backgroundColor:n,borderRadius:"2px",color:"#fff",padding:"0.2rem"}},t)},c={toc:m,Highlight:g};function k(e){let{components:t,...s}=e;return(0,r.kt)("wrapper",(0,a.Z)({},c,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Link prediction")," can be defined as a problem where one wants to predict if there is a link between two nodes in the graph. It can be used for predicting missing or future links in the evolving graph. Using the notation ",(0,r.kt)("inlineCode",{parentName:"p"},"G = (V, E)")," for a graph with nodes ",(0,r.kt)("inlineCode",{parentName:"p"},"V")," and edges ",(0,r.kt)("inlineCode",{parentName:"p"},"E")," and given two nodes ",(0,r.kt)("inlineCode",{parentName:"p"},"v1")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"v2"),", the link prediction algorithm tries to predict whether those two nodes will be connected, based on the ",(0,r.kt)("strong",{parentName:"p"},"node features")," and ",(0,r.kt)("strong",{parentName:"p"},"graph structure"),". Lately, ",(0,r.kt)("strong",{parentName:"p"},"graph neural networks")," have been often used for ",(0,r.kt)("strong",{parentName:"p"},"node-classification")," and ",(0,r.kt)("strong",{parentName:"p"},"link-prediction")," problems. They are extremely useful in numerous interdisciplinary fields of work where is important to incorporate ",(0,r.kt)("strong",{parentName:"p"},"domain-specific")," knowledge to capture more ",(0,r.kt)("strong",{parentName:"p"},"fine-grained")," relationships among the data. Such fields usually involve working with ",(0,r.kt)("strong",{parentName:"p"},"heterogeneous")," and ",(0,r.kt)("strong",{parentName:"p"},"large-scale")," graphs. ",(0,r.kt)("strong",{parentName:"p"},"GNNs")," iteratively update node representations by aggregating the representations of node neighbors and their representation from the previous iteration. Such properties make ",(0,r.kt)("strong",{parentName:"p"},"graph neural networks")," a great tool for various problems we in Memgraph encounter. If your graph is evolving in time, check ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/memgraph/mage/blob/main/python/tgn.py"},"TGN model")," that Memgraph engineers have already developed."),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/memgraph/mage/blob/main/python/link_prediction.py"},(0,r.kt)("img",{parentName:"a",src:"https://img.shields.io/badge/source-link_prediction_with_gnn-FB6E00?logo=github&style=for-the-badge",alt:"docs-source"}))),(0,r.kt)("h3",{id:"blog-posts"},"Blog Posts"),(0,r.kt)("p",null,"The following blog posts explain how we tried to apply link prediction:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://memgraph.com/blog/link-prediction-with-node2vec-in-physics-collaboration-network"},"Node2Vec")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://memgraph.com/blog/building-a-recommendation-system-for-telecommunication-packages-using-graph-neural-networks"},"GNN Link prediction"))),(0,r.kt)("h3",{id:"about-the-query-module"},"About the query module"),(0,r.kt)("p",null,"In this module you can find support for the following interesting features:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"support for both ",(0,r.kt)("strong",{parentName:"li"},"homogeneous")," and ",(0,r.kt)("strong",{parentName:"li"},"heterogeneous")," graphs"),(0,r.kt)("li",{parentName:"ul"},"support for ",(0,r.kt)("strong",{parentName:"li"},"disconnected")," graphs"),(0,r.kt)("li",{parentName:"ul"},"its applicability to use it as a ",(0,r.kt)("strong",{parentName:"li"},"recommendation system")),(0,r.kt)("li",{parentName:"ul"},"a ",(0,r.kt)("strong",{parentName:"li"},"semi-inductive")," link prediction setup where a larger, updated graph is used for the ",(0,r.kt)("strong",{parentName:"li"},"inference")),(0,r.kt)("li",{parentName:"ul"},"an ",(0,r.kt)("strong",{parentName:"li"},"inductive")," link prediction setup in which ",(0,r.kt)("strong",{parentName:"li"},"training")," and ",(0,r.kt)("strong",{parentName:"li"},"inference")," graphs are different"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"transductive")," graph splitting (training and validation sets)"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Graph attention layer")," aggregates information using an attention mechanism from the first-hop neighbourhood. Introduced by ",(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1710.10903.pdf"},"Velickovic et al.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"GraphSAGE layer")," extends the usability of graph neural networks to large-scale graphs. Introduced by ",(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1706.02216.pdf"},"Hamilton et al.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"mlp")," and ",(0,r.kt)("strong",{parentName:"li"},"dot")," predictors are used for combining node scores to edge scores"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"ADAM")," and ",(0,r.kt)("strong",{parentName:"li"},"SGD")," optimizers are used for training neural networks"),(0,r.kt)("li",{parentName:"ul"},"support for ",(0,r.kt)("strong",{parentName:"li"},"batch training")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"parallel graph sampling"),"  is done using multiple threads"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"negative graph sampling")," is a sampling where the final graph consists only of edges that don't exist"),(0,r.kt)("li",{parentName:"ul"},"evaluating the model's ",(0,r.kt)("strong",{parentName:"li"},"training performance")," using a variety of metrics like ",(0,r.kt)("strong",{parentName:"li"},"AUC, Precision, Recall, Accuracy, Confusion matrix")),(0,r.kt)("li",{parentName:"ul"},"evaluating the model's ",(0,r.kt)("strong",{parentName:"li"},"recommendation performance")," with ",(0,r.kt)("strong",{parentName:"li"},"Precision@k, Recall@k, F1@k and Average Precision")," metrics")),(0,r.kt)("p",null,"If you want to try-out our implementation, head to ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage"},"github/memgraph/mage"))," and find ",(0,r.kt)("inlineCode",{parentName:"p"},"python/link_prediction.py"),". Feel free to give us a \u2b50 if you like the code. The easiest way to test ",(0,r.kt)("strong",{parentName:"p"},"link-prediction")," is by downloading ",(0,r.kt)("a",{parentName:"p",href:"https://memgraph.com/download"},"Memgraph Platform")," and using some of the preloaded datasets in ",(0,r.kt)("strong",{parentName:"p"},"Memgraph Lab"),"."),(0,r.kt)("p",null,"There are some things you should be careful about when using ",(0,r.kt)("strong",{parentName:"p"},"link prediction"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"features of all nodes should be called the same (e.g saved as ",(0,r.kt)("strong",{parentName:"li"},"'features'")," property in ",(0,r.kt)("strong",{parentName:"li"},"Memgraph"),")"),(0,r.kt)("li",{parentName:"ul"},"model's performance on the validation set is obtained using ",(0,r.kt)("strong",{parentName:"li"},"transductive")," splitting mode, while ",(0,r.kt)("strong",{parentName:"li"},"inductive")," dataset split is not yet supported. You can find more information about graph splitting on slides of ",(0,r.kt)("a",{parentName:"li",href:"http://web.stanford.edu/class/cs224w/slides/08-GNN-application.pdf"},"Graph Machine Learning course")," offered by ",(0,r.kt)("strong",{parentName:"li"},"Stanford"),"."),(0,r.kt)("li",{parentName:"ul"},"to improve performance, ",(0,r.kt)("strong",{parentName:"li"},"self-loop")," is added to each node with the edge-type set to ",(0,r.kt)("inlineCode",{parentName:"li"},"self")),(0,r.kt)("li",{parentName:"ul"},"the user can set the flag to automatically add ",(0,r.kt)("strong",{parentName:"li"},"reverse edges")," to each existing edge and hence, convert a ",(0,r.kt)("strong",{parentName:"li"},"directed")," graph to a ",(0,r.kt)("strong",{parentName:"li"},"bidirected")," one. If the source and destination nodes of the edge are the same, ",(0,r.kt)("strong",{parentName:"li"},"reverse edge type")," will be the same as the original ",(0,r.kt)("strong",{parentName:"li"},"edge type"),". Otherwise, the prefix ",(0,r.kt)("strong",{parentName:"li"},"rev_")," will be added to the original ",(0,r.kt)("strong",{parentName:"li"},"edge type"),". See the FAQ part to further see why are ",(0,r.kt)("strong",{parentName:"li"},"self-loops")," and ",(0,r.kt)("strong",{parentName:"li"},"reverse edges")," very important in ML training and how you can get into problems if your graph is already ",(0,r.kt)("strong",{parentName:"li"},"undirected")," \ud83e\udd14")),(0,r.kt)("p",null,"Feel free to open a ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage/issues"},"GitHub issue")),"\nor start a discussion on ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://discord.gg/memgraph"},"Discord"))," if you want\nto speed up development."),(0,r.kt)("h3",{id:"usage"},"Usage"),(0,r.kt)("p",null,"The following procedure is expected when using ",(0,r.kt)("strong",{parentName:"p"},"link prediction module"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"set parameters by calling ",(0,r.kt)("inlineCode",{parentName:"li"},"set_model_parameters")," function"),(0,r.kt)("li",{parentName:"ul"},"train a model by calling ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," function"),(0,r.kt)("li",{parentName:"ul"},"inspect training results (optional) by calling ",(0,r.kt)("inlineCode",{parentName:"li"},"get_training_results")," function"),(0,r.kt)("li",{parentName:"ul"},"predict the relationship between two vertices by calling ",(0,r.kt)("inlineCode",{parentName:"li"},"predict")," or"),(0,r.kt)("li",{parentName:"ul"},"call the ",(0,r.kt)("inlineCode",{parentName:"li"},"recommend")," function to find the most likely relationships")),(0,r.kt)("h3",{id:"implementation-details"},"Implementation details"),(0,r.kt)("p",null,"For the underlying ",(0,r.kt)("strong",{parentName:"p"},"GNN")," training we use the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/dmlc/dgl/"},"DGL library"),"."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Fast and memory-efficient message passing primitives for training Graph Neural Networks. Scale to giant graphs via multi-GPU acceleration and distributed training infrastructure."),(0,r.kt)("p",{parentName:"blockquote"},"-- DGL team")),(0,r.kt)("h4",{id:"splitting-the-dataset"},(0,r.kt)("strong",{parentName:"h4"},"Splitting the dataset")),(0,r.kt)("p",null,"If the user specifies ",(0,r.kt)("inlineCode",{parentName:"p"},"split_ratio 1.0"),", the model will train normally on a whole dataset without validating its performance on a validation set. However, if the user-defined split_ratio is a value between 0.0 and 1.0 but the graph is too small to have such a split, an exception will be thrown."),(0,r.kt)("h4",{id:"self-loops"},(0,r.kt)("strong",{parentName:"h4"},"Self-loops")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Self-loop edge")," is added to every node to improve ",(0,r.kt)("strong",{parentName:"p"},"link_prediction")," performance if specified by the user. ",(0,r.kt)("strong",{parentName:"p"},"Self-loop edges")," are added only as ",(0,r.kt)("strong",{parentName:"p"},"edge_type")," ",(0,r.kt)("inlineCode",{parentName:"p"},"self"),", not in any other way, and to enable this, a custom module has been added."),(0,r.kt)("h4",{id:"batch-training"},(0,r.kt)("strong",{parentName:"h4"},"Batch training")),(0,r.kt)("p",null,"In heterogeneous graphs, all edges are used for creating the node\u2019s neighbourhood but trained on only one edge type that can be set by the user."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"For each gradient descent step, we select a mini-batch of nodes whose final representations at the L-th layer are to be computed. We then take all or some of their neighbours at the L\u22121 layer. This process continues until we reach the input. This iterative process builds the dependency graph starting from the output and working backwards to the input, as the figure below shows:")),(0,r.kt)("img",{src:n(58084).Z}),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"-- DGL docs")),(0,r.kt)("p",null,"The reader is encouraged to take a look at the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.dgl.ai/guide/minibatch.html"},"DGL mini-batch explanation")," for more details."),(0,r.kt)("h2",{id:"procedures"},"Procedures"),(0,r.kt)(o.ZP,{mdxType:"RunOnSubgraph"}),(0,r.kt)("p",null,"The link prediction module is organized as a stateful module in which the user can run several methods one after another without losing the context. The user should start with setting the parameters that are going to be used in the training. If the graph is ",(0,r.kt)("strong",{parentName:"p"},"heterogeneous")," (more than one ",(0,r.kt)("strong",{parentName:"p"},"edge type"),"), ",(0,r.kt)("inlineCode",{parentName:"p"},"target_relation")," parameter must be set so the model could distinguish ",(0,r.kt)("strong",{parentName:"p"},"supervision edges")," (edges used in prediction) from ",(0,r.kt)("strong",{parentName:"p"},"message passing edges")," (used for message aggregation). In the case of ",(0,r.kt)("strong",{parentName:"p"},"homogeneous graph"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"target relation")," will be automatically inferred. ",(0,r.kt)("inlineCode",{parentName:"p"},"Node_features_property")," must also be sent by the user to specify where are saved original node features. Those are needed by ",(0,r.kt)("strong",{parentName:"p"},"graph neural networks")," to compute ",(0,r.kt)("strong",{parentName:"p"},"node embeddings"),". All other parameters are optional."),(0,r.kt)("h3",{id:"set_model_parameters"},(0,r.kt)("inlineCode",{parentName:"h3"},"set_model_parameters()")),(0,r.kt)("p",null,"Here is the description of all parameters supported by ",(0,r.kt)("strong",{parentName:"p"},"link prediction")," that you can set by calling the ",(0,r.kt)("inlineCode",{parentName:"p"},"set_model_parameters")," method:"),(0,r.kt)("h4",{id:"input"},(0,r.kt)("strong",{parentName:"h4"},"Input"),":"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Name"),(0,r.kt)("th",{parentName:"tr",align:null},"Type"),(0,r.kt)("th",{parentName:"tr",align:null},"Default"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"hidden_features_size")),(0,r.kt)("td",{parentName:"tr",align:null},"mgp.List","[int]"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"[16, 16]")),(0,r.kt)("td",{parentName:"tr",align:null},"Defines the size of each hidden layer in the architecture. Input feature size is determined automatically while converting the original graph to the DGL compatible one.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"layer_type")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"graph_attn")),(0,r.kt)("td",{parentName:"tr",align:null},"Supported values are ",(0,r.kt)("inlineCode",{parentName:"td"},"graph_sage")," and ",(0,r.kt)("inlineCode",{parentName:"td"},"graph_attn"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"num_epochs")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"100")),(0,r.kt)("td",{parentName:"tr",align:null},"The number of epochs for model training.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"optimizer")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"ADAM")),(0,r.kt)("td",{parentName:"tr",align:null},"Supported values are ",(0,r.kt)("inlineCode",{parentName:"td"},"ADAM")," and ",(0,r.kt)("inlineCode",{parentName:"td"},"SGD"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"learning_rate")),(0,r.kt)("td",{parentName:"tr",align:null},"float"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"0.01")),(0,r.kt)("td",{parentName:"tr",align:null},"Optimizer's learning rate.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"split_ratio")),(0,r.kt)("td",{parentName:"tr",align:null},"float"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"0.8")),(0,r.kt)("td",{parentName:"tr",align:null},"The split ratio between the training and the validation set. There is no test dataset because it's assumed that the user first needs to create new edges in the original dataset to test a model on them.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"node_features_property")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"features")),(0,r.kt)("td",{parentName:"tr",align:null},"Property name where the node features are saved.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"device_type")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"cpu")),(0,r.kt)("td",{parentName:"tr",align:null},"Defines if the model will be trained using the ",(0,r.kt)("inlineCode",{parentName:"td"},"CPU")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"Cuda GPU"),". To run on ",(0,r.kt)("inlineCode",{parentName:"td"},"Cuda GPU"),", check if the system supports it with ",(0,r.kt)("inlineCode",{parentName:"td"},"torch.cuda.is_available()"),", then set this flag to ",(0,r.kt)("inlineCode",{parentName:"td"},"cuda"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"console_log_freq")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"5")),(0,r.kt)("td",{parentName:"tr",align:null},"Specifies how often results will be printed. This also directly specifies which results will be returned as training and validation results when calling the training method.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"checkpoint_freq")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"5")),(0,r.kt)("td",{parentName:"tr",align:null},"Select the number of epochs on which the model will be saved. The model is persisted on disc.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"aggregator")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"mean")),(0,r.kt)("td",{parentName:"tr",align:null},"Aggregator used in GraphSAGE model. Supported values are ",(0,r.kt)("inlineCode",{parentName:"td"},"lstm"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"pool"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"mean")," and ",(0,r.kt)("inlineCode",{parentName:"td"},"gcn"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"metrics")),(0,r.kt)("td",{parentName:"tr",align:null},"mgp.List","[str]"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"[loss, accuracy, auc_score, precision, recall, f1, true_positives, true_negatives, false_positives, false_negatives]")),(0,r.kt)("td",{parentName:"tr",align:null},"Metrics used to evaluate the training model on the validation set. Additionally, epoch information will always be displayed.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"predictor_type")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"dot")),(0,r.kt)("td",{parentName:"tr",align:null},"Type of the predictor. A predictor is used for combining node scores to edge scores. Supported values are ",(0,r.kt)("inlineCode",{parentName:"td"},"dot")," and ",(0,r.kt)("inlineCode",{parentName:"td"},"mlp"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"attn_num_heads")),(0,r.kt)("td",{parentName:"tr",align:null},"List","[int]"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"[4, 1]")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"GAT")," can support the usage of more than one head in each layer except the last one. The size of the list must be the same as the number of layers specified by the ",(0,r.kt)("inlineCode",{parentName:"td"},"hidden_features_size")," parameter.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"tr_acc_patience")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"8")),(0,r.kt)("td",{parentName:"tr",align:null},"Training patience specifies for how many epochs drop in accuracy on the validation set is tolerated before the training is stopped.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"context_save_dir")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},"Path where the model and predictor will be saved every ",(0,r.kt)("inlineCode",{parentName:"td"},"checkpoint_freq")," epochs.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"target_relation")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},"Unique edge type used for training. Users can provide only ",(0,r.kt)("inlineCode",{parentName:"td"},"edge_type")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"tuple of the source node, edge type, dest_node")," if the same ",(0,r.kt)("inlineCode",{parentName:"td"},"edge_type")," is used with more source-destination node combinations.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"num_neg_per_pos_edge")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"1")),(0,r.kt)("td",{parentName:"tr",align:null},"Number of negative edges that will be sampled per one positive edge in the mini-batch training.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"batch_size")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"256")),(0,r.kt)("td",{parentName:"tr",align:null},"Batch size used in both training and validation procedure. It specifies the number of indices in each batch.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"sampling_workers")),(0,r.kt)("td",{parentName:"tr",align:null},"int"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"5")),(0,r.kt)("td",{parentName:"tr",align:null},"Number of workers that will cooperate in the sampling procedure in the training and validation.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"last_activation_function")),(0,r.kt)("td",{parentName:"tr",align:null},"str"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"sigmoid")),(0,r.kt)("td",{parentName:"tr",align:null},"Activation function that is applied after the last layer in the model and before the ",(0,r.kt)("inlineCode",{parentName:"td"},"predictor_type"),". Currently, only ",(0,r.kt)("inlineCode",{parentName:"td"},"sigmoid")," is supported.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"add_reverse_edges")),(0,r.kt)("td",{parentName:"tr",align:null},"bool"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"False")),(0,r.kt)("td",{parentName:"tr",align:null},"Whether the module should add reverse edges for each existing edge in the obtained graph. If the source and destination node are of the same type, edges of the same edge type will be created. If the source and destination nodes are different, then the prefix ",(0,r.kt)("inlineCode",{parentName:"td"},"rev_")," will be added to the previous edge type. Reverse edges will be excluded as message passing edges for corresponding supervision edges.")))),(0,r.kt)("h4",{id:"output"},(0,r.kt)("strong",{parentName:"h4"},"Output"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"status: bool")," -> ",(0,r.kt)("inlineCode",{parentName:"li"},"True")," if all parameters were successfully updated, ",(0,r.kt)("inlineCode",{parentName:"li"},"False")," otherwise."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"message: str")," -> ",(0,r.kt)("inlineCode",{parentName:"li"},"OK")," if all parameters were successfully updated, ",(0,r.kt)("inlineCode",{parentName:"li"},"Error message")," otherwise.")),(0,r.kt)("p",null,"Only those parameters that need changing from their default values are sent when calling the procedure:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'CALL link_prediction.set_model_parameters({num_epochs: 100, node_features_property: "features", tr_acc_patience: 8, target_relation: "CITES", batch_size: 256, last_activation_function: "sigmoid", add_reverse_edges: True})\nYIELD status, message\nRETURN status, message;\n')),(0,r.kt)("h3",{id:"train"},(0,r.kt)("inlineCode",{parentName:"h3"},"train()")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"train")," method doesn't take any parameters, so it is very simple to use."),(0,r.kt)("h4",{id:"output-1"},(0,r.kt)("strong",{parentName:"h4"},"Output"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"training_results: List[Dict[str, float]]")," -> List of training results through epochs. Model's performance is evaluated every ",(0,r.kt)("inlineCode",{parentName:"li"},"console_log_freq")," epochs."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"validation results: List[Dict[str, float]]")," -> List of validation results through epochs. Model's performance is evaluated every ",(0,r.kt)("inlineCode",{parentName:"li"},"console_log_freq")," epochs.")),(0,r.kt)("p",null,"You can just call"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"CALL link_prediction.train()\nYIELD training_results, validation_results\nRETURN training_results, validation_results;\n")),(0,r.kt)("p",null,"to get training and validation results summarized through epochs."),(0,r.kt)("h3",{id:"get_training_results"},(0,r.kt)("inlineCode",{parentName:"h3"},"get_training_results()")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"get_training_results")," method is used when the user wants to get performance data obtained from the last training. It is in the same form as a result of calling the training method. If there is no loaded model, the exception will be thrown."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"CALL link_prediction.get_training_results()\nYIELD training_results, validation_results;\nRETURN training_results, validation_results;\n")),(0,r.kt)("h4",{id:"output-2"},(0,r.kt)("strong",{parentName:"h4"},"Output:")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"training_results: List[Dict[str, float]]")," -> List of training results through epochs. Model's performance is evaluated every ",(0,r.kt)("inlineCode",{parentName:"li"},"console_log_freq")," epochs."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"validation results: List[Dict[str, float]]")," -> List of validation results through epochs. Model's performance is evaluated every ",(0,r.kt)("inlineCode",{parentName:"li"},"console_log_freq")," epochs.")),(0,r.kt)("h3",{id:"predict"},(0,r.kt)("inlineCode",{parentName:"h3"},"predict()")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"predict")," method takes two arguments, ",(0,r.kt)("strong",{parentName:"p"},"src_vertex")," and ",(0,r.kt)("strong",{parentName:"p"},"dest_vertex"),", and predicts whether there is an edge between them or not. It supports an ",(0,r.kt)("inlineCode",{parentName:"p"},"\u201cactual\u201d")," prediction scenario when the edge doesn\u2019t exist and the user wants to predict whether there is an edge or not but also a scenario in which there is an edge between two vertices and the user wants to check the model\u2019s evaluation."),(0,r.kt)("h4",{id:"input-1"},"Input"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"src_vertex: mgp.Vertex")," -> Source vertex of the edge"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"dest_vertex: mgp.Vertex")," -> Destination vertex of the edge.")),(0,r.kt)("h4",{id:"output-3"},"Output"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"score: mgp.Number")," -> Score between 0 and 1 that represents the probability of two nodes being connected.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'MATCH (v1:PAPER {id: "ID_1"})\nMATCH (v2:PAPER {id: "ID_2"})\nCALL link_prediction.predict(v1, v2)\nYIELD score\nRETURN score;\n')),(0,r.kt)("h3",{id:"recommend"},(0,r.kt)("inlineCode",{parentName:"h3"},"recommend()")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"recommend")," method can be used to recommend the best k nodes from ",(0,r.kt)("inlineCode",{parentName:"p"},"dest_vertices")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"src_vertex"),". It is implemented efficiently using the ",(0,r.kt)("strong",{parentName:"p"},"max heap")," data structure. The best nodes are determined based on the edge scores. Metrics specific to recommendation systems (",(0,r.kt)("strong",{parentName:"p"},"precision@k, recall@k, f1@k and average precision"),") are logged to the ",(0,r.kt)("strong",{parentName:"p"},"standard output"),". ",(0,r.kt)("strong",{parentName:"p"},"K")," is equal to the given ",(0,r.kt)("inlineCode",{parentName:"p"},"min(k, length(dest_vertices), length(results))")," where results are a list of all recommendations given by the model(classified as a positive example.)"),(0,r.kt)("h4",{id:"input-2"},"Input"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"src_vertex: mgp.Vertex")," \u2192 Source node."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"dest_vertices: List[mgp.Vertex]")," \u2192 destination nodes. If they are not of the same type, an exception is thrown."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"k: int")," \u2192 Number of edges to recommend.")),(0,r.kt)("h4",{id:"output-4"},"Output"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"score: mgp.Number")," \u2192 Score between 0 and 1 that represents the probability of two nodes being connected."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"recommendation: mgp.Vertex")," \u2192 A reference to the target node.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'MATCH (v1:Customer {id: "8779-QRDMV"})\nMATCH (p:Plan)\nWITH collect(p) AS all_plans, v1\nCALL link_prediction.recommend(v1, all_plans, 5)\nYIELD score, recommendation\nRETURN v1, score, recommendation;\n')),(0,r.kt)("h3",{id:"load_context"},(0,r.kt)("inlineCode",{parentName:"h3"},"load_context()")),(0,r.kt)("p",null,"Loading the context means loading the model and the predictor. If the user specifies the path, the method will try to load it from there. Otherwise, context will be loaded from the default parameter specified in the ",(0,r.kt)("strong",{parentName:"p"},"link_prediction_parameters")," module."),(0,r.kt)("h4",{id:"input-3"},"Input"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"path: str")," \u2192 Path to the folder where the model and the predictor are saved.")),(0,r.kt)("h4",{id:"output-5"},"Output"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"status: mgp.Any")," \u2192 True to indicate that execution went well.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"CALL link_prediction.load_context() YIELD * RETURN *;\n")),(0,r.kt)("h3",{id:"reset_parameters"},(0,r.kt)("inlineCode",{parentName:"h3"},"reset_parameters()")),(0,r.kt)("p",null,"You can explicitly reset parameters whenever you want. Note, however, that parameters will be reset before the training even if not specified because of implementation reasons."),(0,r.kt)("h4",{id:"output-6"},"Output"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"status: mgp.Any")," \u2192 True to indicate that method is successfully finished.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"CALL link_prediction.reset_parameters() YIELD * RETURN *;\n")),(0,r.kt)("h2",{id:"results"},"Results"),(0,r.kt)("p",null,"We extensively tested our model on the ",(0,r.kt)("a",{parentName:"p",href:"https://paperswithcode.com/dataset/cora"},(0,r.kt)("strong",{parentName:"a"},"CORA"))," dataset and the Telecom recommendation dataset. To show you how the training performance could progress through epochs, here are the results for one of our basic models tried on the Cora dataset:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"epoch_num"),(0,r.kt)("th",{parentName:"tr",align:null},"AUC"),(0,r.kt)("th",{parentName:"tr",align:null},"accuracy"),(0,r.kt)("th",{parentName:"tr",align:null},"precision"),(0,r.kt)("th",{parentName:"tr",align:null},"recall"),(0,r.kt)("th",{parentName:"tr",align:null},"f1"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"1"),(0,r.kt)("td",{parentName:"tr",align:null},"0.64"),(0,r.kt)("td",{parentName:"tr",align:null},"0.594"),(0,r.kt)("td",{parentName:"tr",align:null},"0.613"),(0,r.kt)("td",{parentName:"tr",align:null},"0.494"),(0,r.kt)("td",{parentName:"tr",align:null},"0.547")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2"),(0,r.kt)("td",{parentName:"tr",align:null},"0.781"),(0,r.kt)("td",{parentName:"tr",align:null},"0.696"),(0,r.kt)("td",{parentName:"tr",align:null},"0.711"),(0,r.kt)("td",{parentName:"tr",align:null},"0.663"),(0,r.kt)("td",{parentName:"tr",align:null},"0.686")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"3"),(0,r.kt)("td",{parentName:"tr",align:null},"0.798"),(0,r.kt)("td",{parentName:"tr",align:null},"0.729"),(0,r.kt)("td",{parentName:"tr",align:null},"0.752"),(0,r.kt)("td",{parentName:"tr",align:null},"0.682"),(0,r.kt)("td",{parentName:"tr",align:null},"0.715")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"4"),(0,r.kt)("td",{parentName:"tr",align:null},"0.754"),(0,r.kt)("td",{parentName:"tr",align:null},"0.686"),(0,r.kt)("td",{parentName:"tr",align:null},"0.716"),(0,r.kt)("td",{parentName:"tr",align:null},"0.617"),(0,r.kt)("td",{parentName:"tr",align:null},"0.663")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"5"),(0,r.kt)("td",{parentName:"tr",align:null},"0.789"),(0,r.kt)("td",{parentName:"tr",align:null},"0.711"),(0,r.kt)("td",{parentName:"tr",align:null},"0.715"),(0,r.kt)("td",{parentName:"tr",align:null},"0.7"),(0,r.kt)("td",{parentName:"tr",align:null},"0.707")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"6"),(0,r.kt)("td",{parentName:"tr",align:null},"0.813"),(0,r.kt)("td",{parentName:"tr",align:null},"0.756"),(0,r.kt)("td",{parentName:"tr",align:null},"0.742"),(0,r.kt)("td",{parentName:"tr",align:null},"0.784"),(0,r.kt)("td",{parentName:"tr",align:null},"0.763")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"7"),(0,r.kt)("td",{parentName:"tr",align:null},"0.884"),(0,r.kt)("td",{parentName:"tr",align:null},"0.772"),(0,r.kt)("td",{parentName:"tr",align:null},"0.764"),(0,r.kt)("td",{parentName:"tr",align:null},"0.791"),(0,r.kt)("td",{parentName:"tr",align:null},"0.775")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"8"),(0,r.kt)("td",{parentName:"tr",align:null},"0.859"),(0,r.kt)("td",{parentName:"tr",align:null},"0.775"),(0,r.kt)("td",{parentName:"tr",align:null},"0.781"),(0,r.kt)("td",{parentName:"tr",align:null},"0.766"),(0,r.kt)("td",{parentName:"tr",align:null},"0.773")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"9"),(0,r.kt)("td",{parentName:"tr",align:null},"0.871"),(0,r.kt)("td",{parentName:"tr",align:null},"0.805"),(0,r.kt)("td",{parentName:"tr",align:null},"0.822"),(0,r.kt)("td",{parentName:"tr",align:null},"0.777"),(0,r.kt)("td",{parentName:"tr",align:null},"0.798")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"10"),(0,r.kt)("td",{parentName:"tr",align:null},"0.832"),(0,r.kt)("td",{parentName:"tr",align:null},"0.759"),(0,r.kt)("td",{parentName:"tr",align:null},"0.776"),(0,r.kt)("td",{parentName:"tr",align:null},"0.729"),(0,r.kt)("td",{parentName:"tr",align:null},"0.752")))),(0,r.kt)("h2",{id:"example"},"Example"),(0,r.kt)(i.Z,{groupId:"example",defaultValue:"visualization",values:[{label:"Step 1: Input graph",value:"visualization"},{label:"Step 2: Load commands",value:"cypher-load"},{label:"Step 3: Set model parameters",value:"set-model-parameters"},{label:"Step 4: Train",value:"train"},{label:"Step 5: Train results",value:"train-results"},{label:"Step 6: Predict",value:"predict"},{label:"Step 7: Predict results",value:"predict-results"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"visualization",mdxType:"TabItem"},(0,r.kt)("img",{src:n(81965).Z})),(0,r.kt)(l.Z,{value:"cypher-load",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE (v1:PAPER {id: 10, features: [1, 2, 3]});\nCREATE (v2:PAPER {id: 11, features: [1.54, 0.3, 1.78]});\nCREATE (v3:PAPER {id: 12, features: [0.5, 1, 4.5]});\nCREATE (v4:PAPER {id: 13, features: [0.78, 0.234, 1.2]});\nMATCH (v1:PAPER {id: 10}), (v2:PAPER {id: 11}) CREATE (v1)-[e:CITES {}]->(v2);\nMATCH (v2:PAPER {id: 11}), (v3:PAPER {id: 12}) CREATE (v2)-[e:CITES {}]->(v3);\nMATCH (v3:PAPER {id: 12}), (v4:PAPER {id: 13}) CREATE (v3)-[e:CITES {}]->(v4);\nMATCH (v4:PAPER {id: 13}), (v1:PAPER {id: 10}) CREATE (v4)-[e:CITES {}]->(v1);\n"))),(0,r.kt)(l.Z,{value:"set-model-parameters",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},'CALL link_prediction.set_model_parameters({target_relation: ["PAPER", "CITES", "PAPER"], node_features_property: "features",\nsplit_ratio: 1.0, predictor_type: "mlp", num_epochs: 100, hidden_features_size: [256], attn_num_heads: [1]}) YIELD * RETURN *;\n'))),(0,r.kt)(l.Z,{value:"train",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL link_prediction.train() YIELD training_results, validation_results\nRETURN training_results, validation_results;\n"))),(0,r.kt)(l.Z,{value:"train-results",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},"+--------------------+--------------------+--------------------+--------------------+--------------------+\n| epoch_num          | accuracy           | auc_score          | loss               | precision          |\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n| 17                 | 0.833              | 0.906              | 0.428              | 1.0                |\n| 18                 | 0.917              | 0.938              | 0.393              | 1.0                |\n| 19                 | 0.833              | 0.938              | 0.365              | 0.75               |\n| 20                 | 0.917              | 0.938              | 0.341              | 1.0                |\n| 21                 | 0.917              | 0.938              | 0.315              | 1.0                |\n| 22                 | 0.833              | 0.969              | 0.296              | 0.75               |\n| 23                 | 0.917              | 1.0                | 0.277              | 1.0                |\n| 24                 | 0.917              | 1.0                | 0.246              | 0.8                |\n| 25                 | 0.917              | 1.0                | 0.233              | 0.8                |\n| 26                 | 1.0                | 1.0                | 0.202              | 1.0                |\n"))),(0,r.kt)(l.Z,{value:"predict",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"MATCH (v1:PAPER {id: 10})\nMATCH (v2:PAPER {id: 12})\nCALL link_prediction.predict(v1, v2)\nYIELD score\nRETURN score;\n"))),(0,r.kt)(l.Z,{value:"predict-results",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},"+-------+\n| score |\n| 0.104 |\n")))),(0,r.kt)("h2",{id:"faq"},"FAQ"),(0,r.kt)("h3",{id:"why-can-i-get-into-problems-with-reverse-edges"},(0,r.kt)("strong",{parentName:"h3"},"Why can I get into problems with reverse edges?")),(0,r.kt)("p",null,"Having a ",(0,r.kt)("inlineCode",{parentName:"p"},"reverse_edge")," in your dataset can be a problem if they are not excluded from ",(0,r.kt)("inlineCode",{parentName:"p"},"message passing edges")," in the prediction of its ",(0,r.kt)("inlineCode",{parentName:"p"},"opposite edge"),"(",(0,r.kt)("inlineCode",{parentName:"p"},"supervision edge"),"). The best thing you can do is have a ",(0,r.kt)("inlineCode",{parentName:"p"},"directed")," graph and the module will automatically add reverse edges, if you specify ",(0,r.kt)("inlineCode",{parentName:"p"},"add_reverse_edges")," in the ",(0,r.kt)("inlineCode",{parentName:"p"},"set_model_parameters")," method, in a way that doesn't cause information flow."),(0,r.kt)("h3",{id:"what-is-a-transductive-dataset-split"},(0,r.kt)("strong",{parentName:"h3"},"What is a transductive dataset split?")),(0,r.kt)("p",null,"The transductive dataset split assumes that the entire graph can be observed in all dataset splits. We distinguish four types of edges, and those are: ",(0,r.kt)("inlineCode",{parentName:"p"},"validation"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"training"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"message passing")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"supervision edges"),"."),(0,r.kt)("img",{src:n(37097).Z}),(0,r.kt)("p",null,"The transductive dataset split is described in detail by prof. Jure Leskovec at one of its presentations for ",(0,r.kt)("a",{parentName:"p",href:"http://web.stanford.edu/class/cs224w/slides/08-GNN-application.pdf"},"Graph ML course"),"."))}k.isMDXComponent=!0},83523:(e,t,n)=>{n.d(t,{ZP:()=>l});var a=n(87462),r=(n(67294),n(3905));const i={toc:[]};function l(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"If you want to execute this algorithm on graph projections, subgraphs or portions\nof the graph, be sure to check out the guide on\n",(0,r.kt)("a",{parentName:"p",href:"/mage/how-to-guides/run-a-subgraph-module"},"How to run a MAGE module on subgraphs"),".")))}l.isMDXComponent=!0},85162:(e,t,n)=>{n.d(t,{Z:()=>l});var a=n(67294),r=n(86010);const i="tabItem_Ymn6";function l(e){let{children:t,hidden:n,className:l}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(i,l),hidden:n},t)}},74866:(e,t,n)=>{n.d(t,{Z:()=>w});var a=n(87462),r=n(67294),i=n(86010),l=n(12466),o=n(16550),s=n(91980),p=n(67392),d=n(50012);function u(e){return function(e){var t;return(null==(t=r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})))?void 0:t.filter(Boolean))??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}function m(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??u(n);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function g(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function c(e){let{queryString:t=!1,groupId:n}=e;const a=(0,o.k6)(),i=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,s._X)(i),(0,r.useCallback)((e=>{if(!i)return;const t=new URLSearchParams(a.location.search);t.set(i,e),a.replace({...a.location,search:t.toString()})}),[i,a])]}function k(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,i=m(e),[l,o]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!g({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:i}))),[s,p]=c({queryString:n,groupId:a}),[u,k]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,i]=(0,d.Nk)(n);return[a,(0,r.useCallback)((e=>{n&&i.set(e)}),[n,i])]}({groupId:a}),h=(()=>{const e=s??u;return g({value:e,tabValues:i})?e:null})();(0,r.useLayoutEffect)((()=>{h&&o(h)}),[h]);return{selectedValue:l,selectValue:(0,r.useCallback)((e=>{if(!g({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);o(e),p(e),k(e)}),[p,k,i]),tabValues:i}}var h=n(72389);const N="tabList__CuJ",f="tabItem_LNqP";function v(e){let{className:t,block:n,selectedValue:o,selectValue:s,tabValues:p}=e;const d=[],{blockElementScrollPositionUntilNextRender:u}=(0,l.o5)(),m=e=>{const t=e.currentTarget,n=d.indexOf(t),a=p[n].value;a!==o&&(u(t),s(a))},g=e=>{var t;let n=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const t=d.indexOf(e.currentTarget)+1;n=d[t]??d[0];break}case"ArrowLeft":{const t=d.indexOf(e.currentTarget)-1;n=d[t]??d[d.length-1];break}}null==(t=n)||t.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.Z)("tabs",{"tabs--block":n},t)},p.map((e=>{let{value:t,label:n,attributes:l}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:o===t?0:-1,"aria-selected":o===t,key:t,ref:e=>d.push(e),onKeyDown:g,onClick:m},l,{className:(0,i.Z)("tabs__item",f,null==l?void 0:l.className,{"tabs__item--active":o===t})}),n??t)})))}function b(e){let{lazy:t,children:n,selectedValue:a}=e;const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},i.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function y(e){const t=k(e);return r.createElement("div",{className:(0,i.Z)("tabs-container",N)},r.createElement(v,(0,a.Z)({},e,t)),r.createElement(b,(0,a.Z)({},e,t)))}function w(e){const t=(0,h.Z)();return r.createElement(y,(0,a.Z)({key:String(t)},e))}},81965:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/gnn-link-prediction-example-visualization-22c2d1ab4bd9680c02aa4126e7689719.png"},58084:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/gnn-link-prediction-neighborhood-sampling-3a0c7576f637e87326632a534d4ae772.png"},37097:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/gnn-link-prediction-transductive-dataset-split-c3c2264a6e276518317dd493078f2534.png"}}]);
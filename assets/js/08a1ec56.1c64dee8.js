"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3594],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return u}});var r=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),m=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=m(e.components);return r.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=m(a),u=n,g=d["".concat(l,".").concat(u)]||d[u]||c[u]||o;return a?r.createElement(g,i(i({ref:t},p),{},{components:a})):r.createElement(g,i({ref:t},p))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:n,i[1]=s;for(var m=2;m<o;m++)i[m]=a[m];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}d.displayName="MDXCreateElement"},85437:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return m},toc:function(){return p},default:function(){return d}});var r=a(87462),n=a(63366),o=(a(67294),a(3905)),i=["components"],s={id:"avro",title:"Import Avro data",sidebar_label:"Avro"},l=void 0,m={unversionedId:"import-data/kafka/avro",id:"version-2.1.0/import-data/kafka/avro",title:"Import Avro data",description:"If you want to import your data in Memgraph using Apache Avro serialization, you",source:"@site/memgraph_versioned_docs/version-2.1.0/import-data/kafka/avro.md",sourceDirName:"import-data/kafka",slug:"/import-data/kafka/avro",permalink:"/docs/memgraph/2.1.0/import-data/kafka/avro",editUrl:"https://github.com/memgraph/docs/tree/master/memgraph_versioned_docs/version-2.1.0/import-data/kafka/avro.md",tags:[],version:"2.1.0",frontMatter:{id:"avro",title:"Import Avro data",sidebar_label:"Avro"},sidebar:"version-2.1.0/memgraph",previous:{title:"Kafka streams overview",permalink:"/docs/memgraph/2.1.0/import-data/kafka"},next:{title:"JSON",permalink:"/docs/memgraph/2.1.0/import-data/kafka/json"}},p=[{value:"Datatype mapping",id:"datatype-mapping",children:[],level:2},{value:"Example",id:"example",children:[{value:"Deserialization",id:"deserialization",children:[],level:3},{value:"Transformation modules",id:"transformation-modules",children:[],level:3},{value:"Creating streams",id:"creating-streams",children:[],level:3}],level:2},{value:"Next steps",id:"next-steps",children:[],level:2}],c={toc:p};function d(e){var t=e.components,s=(0,n.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},c,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"If you want to import your data in Memgraph using Apache Avro serialization, you\nneed to know the ",(0,o.kt)("a",{parentName:"p",href:"https://avro.apache.org/docs/current/gettingstartedpython.html#Defining+a+schema"},"Avro\nschema"),"\nof your data. This is necessary for deserializing the data. Each schema contains\na single schema definition, so there should be a separate schema for each data\nrepresentation you want to import into Memgraph."),(0,o.kt)("h2",{id:"datatype-mapping"},"Datatype mapping"),(0,o.kt)("p",null,"Avro data types will be flexibly mapped to the target schema; that is, Avro and\nopenCypher types do not need to match exactly. Use the table below for data type\nmappings:"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Avro Data Type"),(0,o.kt)("th",{parentName:"tr",align:null},"Cypher Casting Function"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"bool"),(0,o.kt)("td",{parentName:"tr",align:null},"toBoolean")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"float"),(0,o.kt)("td",{parentName:"tr",align:null},"toFloat")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"int"),(0,o.kt)("td",{parentName:"tr",align:null},"toInteger")))),(0,o.kt)("h2",{id:"example"},"Example"),(0,o.kt)("p",null,"Let's assume we have the following schemas coming out of their respective topics\n",(0,o.kt)("inlineCode",{parentName:"p"},"avroStreamProfile"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"avroStreamCompany"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"avroStreamWorksAt"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'profile_schema = """ {\n    "namespace": "example.avro",\n    "name": "Person",\n    "type": "record",\n    "fields": [\n        {"name": "name", "type": "string"},\n        {"name": "age", "type": "int"},\n        {"name": "email", "type": "string"},\n        {"name": "address", "type": "string"}\n    ]\n}"""\n\ncompany_schema = """{\n    "namespace": "example.avro",\n    "name": "Company",\n    "type": "record",\n    "fields": [\n        {"name": "name", "type": "string"},\n        {"name": "address", "type": "string"}\n    ]\n} """\n\nworks_at_schema = """ {\n    "namespace": "example.avro",\n    "name": "Works_At",\n    "type": "record",\n    "fields": [\n        {"name": "name", "type": "string"},\n        {"name": "company", "type": "string"}\n    ]\n}\n"""\n')),(0,o.kt)("p",null,"We can use the schemas to build the following graph:"),(0,o.kt)("img",{src:a(4108).Z,height:"300px"}),(0,o.kt)("h3",{id:"deserialization"},"Deserialization"),(0,o.kt)("p",null,"Data received by the Memgraph consumer is a byte array and needs to be\ndeserialized. The following method will help you deserialize your data with the\nhelp of Confluent Kafka:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from confluent_kafka.schema_registry import SchemaRegistryClient\nfrom confluent_kafka.schema_registry.avro import AvroDeserializer\n\ndef process_record_confluent(record: bytes, src: SchemaRegistryClient, schema: str):\n    deserializer = AvroDeserializer(schema_str=schema, schema_registry_client=src)\n    return deserializer(record, None) # returns dict\n\n")),(0,o.kt)("h3",{id:"transformation-modules"},"Transformation modules"),(0,o.kt)("p",null,"Before consuming data from a stream, we need to implement transformation modules\nthat will produce queries. In order to create a transformation module, you need\nto:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Create a Python module"),(0,o.kt)("li",{parentName:"ol"},"Save it into the Memgraph's query-modules directory (default:\n",(0,o.kt)("inlineCode",{parentName:"li"},"/usr/lib/memgraph/query_modules"),")"),(0,o.kt)("li",{parentName:"ol"},"Load it into Memgraph either on startup (automatically) or by running the\n",(0,o.kt)("inlineCode",{parentName:"li"},"CALL mg.load_all")," query")),(0,o.kt)("p",null,"Example for the ",(0,o.kt)("inlineCode",{parentName:"p"},"profile_transformation")," module:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'@mgp.transformation\ndef profile_transformation(messages: mgp.Messages) -> mgp.Record(query = str, parameters=mgp.Nullable[mgp.Map]):\n    result_queries = []\n\n    for i in range(messages.total_messages()):\n        message_avro = messages.message_at(i)\n        msg_value = message_avro.payload()\n        message = process_record_confluent(msg_value, src= SchemaRegistryClient({\'url\': \'http://localhost:8081\'}), schema=profile_schema)\n        result_queries.append(mgp.Record (\n                query=f\'CREATE (p: Person {{ name: "{message["name"]}", age: ToInteger({message["age"]}), address: "{message["address"]}", email:"{message["email"]}" }});\' ,\n                parameters=None\n            ))\n\n    return result_queries\n\n')),(0,o.kt)("h3",{id:"creating-streams"},"Creating streams"),(0,o.kt)("p",null,"To import data into Memgraph, we need to create a stream for each topic and\napply our transformation module on incoming data:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE STREAM avroStreamProfile TOPICS avro-stream-profile TRANSFORM avro_transform.profile_transformation;\nCREATE STREAM avroStreamCompany TOPICS avro-stream-company TRANSFORM avro_transform.company_transformation;\nCREATE STREAM avroStreamWorksAt TOPICS avro-stream-worksat TRANSFORM avro_transform.works_at_transformation;\n")),(0,o.kt)("p",null,"To start the streams, execute the following query:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"START ALL STREAMS;\n")),(0,o.kt)("p",null,"Run the following query to check if all the streams were started correctly:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"SHOW STREAMS;\n")),(0,o.kt)("p",null,"You can also check the node counter in ",(0,o.kt)("strong",{parentName:"p"},"Memgraph Lab")," (",(0,o.kt)("strong",{parentName:"p"},"Overview tab"),") to\nsee if new nodes and relationships are arriving."),(0,o.kt)("h2",{id:"next-steps"},"Next steps"),(0,o.kt)("p",null,"Check out the example-streaming-app on\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/memgraph/example-streaming-app"},"GitHub")," to see how Memgraph\ncan be connected to a Kafka stream."))}d.isMDXComponent=!0},4108:function(e,t,a){t.Z=a.p+"assets/images/kafka-graph-e4e8c68495826bbe558fbeadb1abc14d.png"}}]);
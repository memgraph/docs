"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53771],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>g});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),s=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),u=s(a),g=r,c=u["".concat(p,".").concat(g)]||u[g]||d[g]||l;return a?n.createElement(c,i(i({ref:t},m),{},{components:a})):n.createElement(c,i({ref:t},m))}));function g(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=u;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var s=2;s<l;s++)i[s]=a[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},85007:(e,t,a)=>{a.r(t),a.d(t,{Highlight:()=>g,assets:()=>d,contentTitle:()=>s,default:()=>k,frontMatter:()=>p,metadata:()=>m,toc:()=>u});var n=a(87462),r=(a(67294),a(3905)),l=a(65488),i=a(85162),o=a(83523);const p={id:"temporal-graph-networks",title:"temporal_graph_networks",sidebar_label:"temporal_graph_networks"},s=void 0,m={unversionedId:"query-modules/python/temporal-graph-networks",id:"query-modules/python/temporal-graph-networks",title:"temporal_graph_networks",description:"docs-source",source:"@site/mage/query-modules/python/temporal-graph-networks.md",sourceDirName:"query-modules/python",slug:"/query-modules/python/temporal-graph-networks",permalink:"/docs/mage/query-modules/python/temporal-graph-networks",draft:!1,editUrl:"https://github.com/memgraph/docs/tree/master/mage/query-modules/python/temporal-graph-networks.md",tags:[],version:"current",frontMatter:{id:"temporal-graph-networks",title:"temporal_graph_networks",sidebar_label:"temporal_graph_networks"},sidebar:"mage",previous:{title:"set_cover",permalink:"/docs/mage/query-modules/python/set-cover"},next:{title:"tsp",permalink:"/docs/mage/query-modules/python/tsp"}},d={},u=[{value:"Abstract",id:"abstract",level:2},{value:"About the query module",id:"about-the-query-module",level:3},{value:"Usage",id:"usage",level:3},{value:"Implementation details",id:"implementation-details",level:3},{value:"Query module",id:"query-module",level:4},{value:"Processing one batch",id:"processing-one-batch",level:4},{value:"Procedures",id:"procedures",level:2},{value:"<code>set_params(params)</code>",id:"set_paramsparams",level:3},{value:"Input:",id:"input",level:4},{value:"Usage:",id:"usage-1",level:4},{value:"<code>update(edges)</code>",id:"updateedges",level:3},{value:"Input:",id:"input-1",level:4},{value:"Usage:",id:"usage-2",level:4},{value:"<code>get()</code>",id:"get",level:3},{value:"Output:",id:"output",level:4},{value:"Usage:",id:"usage-3",level:4},{value:"<code>set_eval()</code>",id:"set_eval",level:3},{value:"Usage:",id:"usage-4",level:4},{value:"<code>get_results()</code>",id:"get_results",level:3},{value:"Output:",id:"output-1",level:4},{value:"Usage:",id:"usage-5",level:4},{value:"<code>train_and_eval(num_epochs)</code>",id:"train_and_evalnum_epochs",level:3},{value:"Input:",id:"input-2",level:4},{value:"Output:",id:"output-2",level:4},{value:"Usage:",id:"usage-6",level:4},{value:"<code>predict_link_score(vertex_1, vertex_2)</code>",id:"predict_link_scorevertex_1-vertex_2",level:3},{value:"Input:",id:"input-3",level:4},{value:"Output:",id:"output-3",level:4},{value:"Usage:",id:"usage-7",level:4},{value:"Example",id:"example",level:2}],g=e=>{let{children:t,color:a}=e;return(0,r.kt)("span",{style:{backgroundColor:a,borderRadius:"2px",color:"#fff",padding:"0.2rem"}},t)},c={toc:u,Highlight:g};function k(e){let{components:t,...p}=e;return(0,r.kt)("wrapper",(0,n.Z)({},c,p,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/memgraph/mage/blob/main/python/tgn.py"},(0,r.kt)("img",{parentName:"a",src:"https://img.shields.io/badge/source-temporal_graph_networks-FB6E00?logo=github&style=for-the-badge",alt:"docs-source"}))),(0,r.kt)("h2",{id:"abstract"},"Abstract"),(0,r.kt)("p",null,"The ",(0,r.kt)("strong",{parentName:"p"},"temporal_graph_networks (TGNs)")," are a type of ",(0,r.kt)("a",{parentName:"p",href:"https://distill.pub/2021/gnn-intro/"},"graph neural network\n(GNN)")," for dynamic graphs. In recent years,\n",(0,r.kt)("strong",{parentName:"p"},"GNNs")," have become very popular due to their ability to perform a wide variety\nof machine learning tasks on graphs, such as link prediction, node\nclassification, and so on. This rise started with ",(0,r.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1609.02907.pdf"},"Graph convolutional networks\n(GCN)")," introduced by ",(0,r.kt)("em",{parentName:"p"},"Kipf et al."),",\nfollowed by ",(0,r.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1706.02216.pdf"},"GraphSAGE")," introduced by\n",(0,r.kt)("em",{parentName:"p"},"Hamilton et al."),", and recently a new method that introduces the ",(0,r.kt)("strong",{parentName:"p"},"attention\nmechanism")," to graphs was presented - ",(0,r.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1710.10903.pdf?ref=https://githubhelp.com"},"Graph attention networks\n(GAT)"),", by\n",(0,r.kt)("em",{parentName:"p"},"Veli\u010dkovi\u0107 et al"),". The last two methods offer a great possibility for inductive\nlearning. But they haven't been specifically developed to handle different\nevents occurring on graphs, such as ",(0,r.kt)("strong",{parentName:"p"},"node features updates"),", ",(0,r.kt)("strong",{parentName:"p"},"node\ndeletion"),", ",(0,r.kt)("strong",{parentName:"p"},"edge deletion")," and so on. These events happen regularly in\n",(0,r.kt)("strong",{parentName:"p"},"real-world")," examples such as the ",(0,r.kt)("a",{parentName:"p",href:"https://twitter.com/memgraphmage"},"Twitter\nnetwork"),", where users update their profile,\ndelete their profile or just unfollow another user."),(0,r.kt)("p",null,"In their work, Rossi et al. introduce ",(0,r.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2006.10637"},"Temporal graph\nnetworks"),", an architecture for machine\nlearning on streamed graphs, a rapidly-growing ML use case."),(0,r.kt)("h3",{id:"about-the-query-module"},"About the query module"),(0,r.kt)("p",null,"What we have got in this module:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"link prediction")," - train your ",(0,r.kt)("strong",{parentName:"li"},"TGN")," to predict new ",(0,r.kt)("strong",{parentName:"li"},"links/edges")," and\n",(0,r.kt)("strong",{parentName:"li"},"node classification")," - predict labels of nodes from graph structure and\n",(0,r.kt)("strong",{parentName:"li"},"node/edge")," features"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"graph attention layer")," embedding calculation and ",(0,r.kt)("strong",{parentName:"li"},"graph sum layer"),"\nembedding layer calculation"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"mean")," and ",(0,r.kt)("strong",{parentName:"li"},"last")," as message aggregators"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"mlp")," and ",(0,r.kt)("strong",{parentName:"li"},"identity(concatenation)")," as message functions"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"gru")," and ",(0,r.kt)("strong",{parentName:"li"},"rnn")," as memory updater"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"uniform")," temporal neighborhood sampler"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"memory")," store and ",(0,r.kt)("strong",{parentName:"li"},"raw message store"))),(0,r.kt)("p",null,"as introduced by ",(0,r.kt)("a",{parentName:"p",href:"https://emanuelerossi.co.uk/"},"Rossi et al."),"."),(0,r.kt)("p",null,"The following means ",(0,r.kt)("strong",{parentName:"p"},"you")," can use ",(0,r.kt)("strong",{parentName:"p"},"TGN")," to ",(0,r.kt)("strong",{parentName:"p"},"predict edges")," or perform\n",(0,r.kt)("strong",{parentName:"p"},"node classification")," tasks, with ",(0,r.kt)("strong",{parentName:"p"},"graph attention layer")," or ",(0,r.kt)("strong",{parentName:"p"},"graph sum\nlayer"),", by using either ",(0,r.kt)("strong",{parentName:"p"},"mean")," or ",(0,r.kt)("strong",{parentName:"p"},"last")," as message aggregator, ",(0,r.kt)("strong",{parentName:"p"},"mlp")," or\n",(0,r.kt)("strong",{parentName:"p"},"identity")," as message function, and finally ",(0,r.kt)("strong",{parentName:"p"},"gru")," or ",(0,r.kt)("strong",{parentName:"p"},"rnn")," as memory\nupdater."),(0,r.kt)("p",null,"In total, this gives ",(0,r.kt)("em",{parentName:"p"},"you")," ",(0,r.kt)("strong",{parentName:"p"},"2\u27152\u27152\u27152\u27152 options"),", that is, ",(0,r.kt)("strong",{parentName:"p"},"32")," options to\nexplore on your graph! \ud83d\ude04"),(0,r.kt)("p",null,"If you want to explore our implementation, jump to\n",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage"},"github/memgraph/mage"))," and find\n",(0,r.kt)("inlineCode",{parentName:"p"},"python/tgn.py"),". You can also jump to the ",(0,r.kt)("a",{parentName:"p",href:"https://memgraph.com/download"},"download\npage"),", download ",(0,r.kt)("strong",{parentName:"p"},"Memgraph Platform")," and fire up\n",(0,r.kt)("strong",{parentName:"p"},"TGN"),". We have prepared an ",(0,r.kt)("strong",{parentName:"p"},"Amazon user-item")," dataset on which you can\nexplore link prediction using a ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/jupyter-memgraph-tutorials"},"Jupyter\nNotebook"))),(0,r.kt)("p",null,"What is ",(0,r.kt)("strong",{parentName:"p"},"not")," implemented in the module:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"node update/deletion events")," since they occur very rarely - although we\nhave prepared a codebase to easily integrate them."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"edge deletion")," events"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"time projection")," embedding calculation and ",(0,r.kt)("strong",{parentName:"li"},"identity")," embedding\ncalculation since the author mentions they perform very poorly on all datasets",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"although it is trivial to add a new layer")))),(0,r.kt)("p",null,"Feel free to open a ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage/issues"},"GitHub issue")),"\nor start a discussion on ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://discord.gg/memgraph"},"Discord"))," if you want\nto speed up development."),(0,r.kt)("p",null,"How should ",(0,r.kt)("strong",{parentName:"p"},"you")," use the following module? Prepare Cypher queries, and split\nthem into a ",(0,r.kt)("strong",{parentName:"p"},"train")," set and ",(0,r.kt)("strong",{parentName:"p"},"eval")," set. Don't forget to call the ",(0,r.kt)("inlineCode",{parentName:"p"},"set_mode"),"\nmethod. Every result is stored so that you can easily get it with the module.\nThe module reports the ",(0,r.kt)("a",{parentName:"p",href:"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html"},"mean average\nprecision"),"\nfor every batch ",(0,r.kt)("em",{parentName:"p"},"training")," or ",(0,r.kt)("em",{parentName:"p"},"evaluation")," done."),(0,r.kt)("h3",{id:"usage"},"Usage"),(0,r.kt)("p",null,"The following procedure is expected when using ",(0,r.kt)("strong",{parentName:"p"},"TGN"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"set parameters by calling ",(0,r.kt)("inlineCode",{parentName:"li"},"set_params()")," function"),(0,r.kt)("li",{parentName:"ul"},"set trigger on edge create event to call ",(0,r.kt)("inlineCode",{parentName:"li"},"update()")," function"),(0,r.kt)("li",{parentName:"ul"},"start loading your ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," queries"),(0,r.kt)("li",{parentName:"ul"},"when ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," queries are loaded, switch ",(0,r.kt)("strong",{parentName:"li"},"TGN")," mode to ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," by calling\n",(0,r.kt)("inlineCode",{parentName:"li"},"set_eval()")," function"),(0,r.kt)("li",{parentName:"ul"},"load ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," queries"),(0,r.kt)("li",{parentName:"ul"},"do a few more epochs of training and evaluation to get the best results by\ncalling ",(0,r.kt)("inlineCode",{parentName:"li"},"train_and_eval()"))),(0,r.kt)("p",null,"One thing is important to mention: by calling ",(0,r.kt)("inlineCode",{parentName:"p"},"set_eval()")," function you change\nthe mode of ",(0,r.kt)("strong",{parentName:"p"},"temporal graph networks")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"eval")," mode. Any new edges which\narrive will ",(0,r.kt)("strong",{parentName:"p"},"not")," be used to ",(0,r.kt)("inlineCode",{parentName:"p"},"train")," the module, but to ",(0,r.kt)("inlineCode",{parentName:"p"},"eval"),"."),(0,r.kt)("h3",{id:"implementation-details"},"Implementation details"),(0,r.kt)("h4",{id:"query-module"},"Query module"),(0,r.kt)("p",null,"The module is implemented using ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://pytorch.org/"},"PyTorch")),". From the\ninput (",(0,r.kt)("inlineCode",{parentName:"p"},"mgp.Edge")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"mgp.Vertex")," labels), ",(0,r.kt)("inlineCode",{parentName:"p"},"edge features")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"node features"),"\nare extracted. With a trigger set, the ",(0,r.kt)("inlineCode",{parentName:"p"},"update")," query module procedure will\nparse all new edges and extract the information the ",(0,r.kt)("strong",{parentName:"p"},"TGN")," needs to do batch by\nbatch processing."),(0,r.kt)("p",null,"On the following piece of code, ",(0,r.kt)("em",{parentName:"p"},"you")," can see what is extracted from edges while\nthe ",(0,r.kt)("strong",{parentName:"p"},"batch")," is filling up. When the current processing batch size reaches\n",(0,r.kt)("inlineCode",{parentName:"p"},"batch size")," (predefined in ",(0,r.kt)("inlineCode",{parentName:"p"},"set()"),"), we ",(0,r.kt)("strong",{parentName:"p"},"forward")," the extracted information\nto the ",(0,r.kt)("strong",{parentName:"p"},"TGN"),", which extends ",(0,r.kt)("inlineCode",{parentName:"p"},"torch.nn.Module"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"@dataclasses.dataclass\nclass QueryModuleTGNBatch:\n    current_batch_size: int\n    sources: np.array\n    destinations: np.array\n    timestamps: np.array\n    edge_idxs: np.array\n    node_features: Dict[int, torch.Tensor]\n    edge_features: Dict[int, torch.Tensor]\n    batch_size: int\n    labels: np.array\n")),(0,r.kt)("h4",{id:"processing-one-batch"},"Processing one batch"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"        self._process_previous_batches()\n\n        graph_data = self._get_graph_data(\n            np.concatenate([sources.copy(), destinations.copy()], dtype=int),\n            np.concatenate([timestamps, timestamps]),\n        )\n\n        embeddings = self.tgn_net(graph_data)\n\n        ... process negative edges in a similar way\n\n        self._process_current_batch(\n            sources, destinations, node_features, edge_features, edge_idxs, timestamps\n        )\n")),(0,r.kt)("p",null,"Our ",(0,r.kt)("inlineCode",{parentName:"p"},"torch.nn.Module")," is organized as follows:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"processing previous batches - as in the ",(0,r.kt)("em",{parentName:"li"},(0,r.kt)("a",{parentName:"em",href:"https://arxiv.org/abs/2006.10637"},"research\npaper"))," this will include new computation of\nmessages collected for each node with a ",(0,r.kt)("strong",{parentName:"li"},"message function"),", aggregation of\nmessages for each node with a ",(0,r.kt)("strong",{parentName:"li"},"message aggregator")," and finally updating of\neach node's memory with a ",(0,r.kt)("strong",{parentName:"li"},"memory updater")),(0,r.kt)("li",{parentName:"ul"},"afterward, we create a computation graph used by the ",(0,r.kt)("strong",{parentName:"li"},"graph attention layer"),"\nor ",(0,r.kt)("strong",{parentName:"li"},"graph sum layer")),(0,r.kt)("li",{parentName:"ul"},"the final step includes processing the current batch, creating new\n",(0,r.kt)("strong",{parentName:"li"},"interaction")," or ",(0,r.kt)("strong",{parentName:"li"},"node events"),", and updating the ",(0,r.kt)("strong",{parentName:"li"},"raw message store"),"\nwith new ",(0,r.kt)("strong",{parentName:"li"},"events"))),(0,r.kt)("p",null,"The process repeats: as we get new edges in a batch, the batch fills, and the\nnew edges are forwarded to the ",(0,r.kt)("strong",{parentName:"p"},"TGN")," and so on."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"This ",(0,r.kt)("strong",{parentName:"p"},"MAGE")," module is still in its early stage. We intend to use it only for\n",(0,r.kt)("strong",{parentName:"p"},"learning")," activities. The current state of the module is that you need to\nmanually switch the TGN mode to ",(0,r.kt)("inlineCode",{parentName:"p"},"eval"),". After the switch, incoming edges will be\nused for ",(0,r.kt)("strong",{parentName:"p"},"evaluation")," only. If you wish to make it production-ready, make sure\nto either open a ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/memgraph/mage/issues"},"GitHub issue"))," or\ndrop us a comment on ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://discord.gg/memgraph"},"Discord")),". Also, consider\nthrowing us a \u2b50 so we can continue to do even better work.")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Trait"),(0,r.kt)("th",{parentName:"tr",align:null},"Value"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"Module type")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)(g,{color:"#FB6E00",mdxType:"Highlight"},(0,r.kt)("strong",{parentName:"td"},"module")))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"Implementation")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)(g,{color:"#FB6E00",mdxType:"Highlight"},(0,r.kt)("strong",{parentName:"td"},"Python")))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"Graph direction")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)(g,{color:"#FB6E00",mdxType:"Highlight"},(0,r.kt)("strong",{parentName:"td"},"directed")))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"Edge weights")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)(g,{color:"#FB6E00",mdxType:"Highlight"},(0,r.kt)("strong",{parentName:"td"},"weighted/unweighted")))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"Parallelism")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)(g,{color:"#FB6E00",mdxType:"Highlight"},(0,r.kt)("strong",{parentName:"td"},"sequential")))))),(0,r.kt)("h2",{id:"procedures"},"Procedures"),(0,r.kt)(o.ZP,{mdxType:"RunOnSubgraph"}),(0,r.kt)("h3",{id:"set_paramsparams"},(0,r.kt)("inlineCode",{parentName:"h3"},"set_params(params)")),(0,r.kt)("p",null,"We have defined ",(0,r.kt)("inlineCode",{parentName:"p"},"default")," value for each of the parameters. If you wish to\nchange any of them, call the method with the defined new value."),(0,r.kt)("h4",{id:"input"},"Input:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"params: mgp.Map")," \u27a1 a dictionary containing the following parameters:")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Name"),(0,r.kt)("th",{parentName:"tr",align:null},"Type"),(0,r.kt)("th",{parentName:"tr",align:null},"Default"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"learning_type"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"self_supervised")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"self_supervised")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"supervised")," depending on if you want to predict edges or node labels")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"batch_size"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"200"),(0,r.kt)("td",{parentName:"tr",align:null},"size of batch to process by TGN, recommended size ",(0,r.kt)("strong",{parentName:"td"},"200"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"num_of_layers"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"2"),(0,r.kt)("td",{parentName:"tr",align:null},"number of layers of graph neural network, ",(0,r.kt)("strong",{parentName:"td"},"2")," is the optimal size, GNNs perform worse with more layers in terms of time needed to train, but the gain in accuracy is not significant")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"layer_type"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"graph_attn")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"graph_attn")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"graph_sum")," layer type as defined in the original paper")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"memory_dimension"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"100"),(0,r.kt)("td",{parentName:"tr",align:null},"dimension of memory tensor of each node")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"time_dimension"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"100"),(0,r.kt)("td",{parentName:"tr",align:null},"dimension of time vector from ",(0,r.kt)("inlineCode",{parentName:"td"},"time2vec")," paper")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"num_edge_features"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"50"),(0,r.kt)("td",{parentName:"tr",align:null},"number of edge features we will use from each edge")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"num_node_features"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"50"),(0,r.kt)("td",{parentName:"tr",align:null},"number of expected node features")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"message_dimension"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"100"),(0,r.kt)("td",{parentName:"tr",align:null},"dimension of the message, only used if you use MLP as the message function type, otherwise ignored")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"num_neighbors"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"15"),(0,r.kt)("td",{parentName:"tr",align:null},"number of sampled neighbors")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"edge_message_function_type"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"identity")),(0,r.kt)("td",{parentName:"tr",align:null},"message function type, ",(0,r.kt)("inlineCode",{parentName:"td"},"identity")," for concatenation or ",(0,r.kt)("inlineCode",{parentName:"td"},"mlp")," for projection")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"message_aggregator_type"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"last")),(0,r.kt)("td",{parentName:"tr",align:null},"message aggregator type, ",(0,r.kt)("inlineCode",{parentName:"td"},"mean")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"last"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"memory_updater_type"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"gru")),(0,r.kt)("td",{parentName:"tr",align:null},"memory updater type, ",(0,r.kt)("inlineCode",{parentName:"td"},"gru")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"rnn"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"num_attention_heads"),(0,r.kt)("td",{parentName:"tr",align:null},"Integer"),(0,r.kt)("td",{parentName:"tr",align:null},"1"),(0,r.kt)("td",{parentName:"tr",align:null},"number of attention heads used if you define ",(0,r.kt)("inlineCode",{parentName:"td"},"graph_attn")," as layer type")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"learning_rate"),(0,r.kt)("td",{parentName:"tr",align:null},"Float"),(0,r.kt)("td",{parentName:"tr",align:null},"1e-4"),(0,r.kt)("td",{parentName:"tr",align:null},"learning rate for ",(0,r.kt)("inlineCode",{parentName:"td"},"adam")," optimizer")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"weight_decay"),(0,r.kt)("td",{parentName:"tr",align:null},"Float"),(0,r.kt)("td",{parentName:"tr",align:null},"5e-5"),(0,r.kt)("td",{parentName:"tr",align:null},"weight decay used in ",(0,r.kt)("inlineCode",{parentName:"td"},"adam")," optimizer")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"device_type"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"cuda")),(0,r.kt)("td",{parentName:"tr",align:null},"type of device you want to use for training - ",(0,r.kt)("inlineCode",{parentName:"td"},"cuda")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"cpu"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"node_features_property"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"features")),(0,r.kt)("td",{parentName:"tr",align:null},"name of features property on nodes from which we read features")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"edge_features_property"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"features")),(0,r.kt)("td",{parentName:"tr",align:null},"name of features property on edges from which we read features")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"node_label_property"),(0,r.kt)("td",{parentName:"tr",align:null},"String"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"label")),(0,r.kt)("td",{parentName:"tr",align:null},"name of label property on nodes from which we read features")))),(0,r.kt)("h4",{id:"usage-1"},"Usage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"}," CALL tgn.set_params({learning_type:'self_supervised', batch_size:200, num_of_layers:2,\n                      layer_type:'graph_attn',memory_dimension:20, time_dimension:50,\n                      num_edge_features:20, num_node_features:20, message_dimension:100,\n                      num_neighbors:15, edge_message_function_type:'identity',\n                      message_aggregator_type:'last', memory_updater_type:'gru', num_attention_heads:1});\n")),(0,r.kt)("h3",{id:"updateedges"},(0,r.kt)("inlineCode",{parentName:"h3"},"update(edges)")),(0,r.kt)("p",null,"This function scrapes data from edges, including ",(0,r.kt)("inlineCode",{parentName:"p"},"edge_features")," and\n",(0,r.kt)("inlineCode",{parentName:"p"},"node_features")," if they exist, and fills up the batch. If the batch is ready the\n",(0,r.kt)("strong",{parentName:"p"},"TGN")," will process it and be ready to accept new incoming edges."),(0,r.kt)("h4",{id:"input-1"},"Input:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"edges: mgp.List[mgp.Edges]")," \u27a1 List of edges to preprocess (that arrive in a\nstream to Memgraph). If a batch is full, ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," starts, depending\non the mode.")),(0,r.kt)("h4",{id:"usage-2"},"Usage:"),(0,r.kt)("p",null,"There are a few options here:"),(0,r.kt)("p",null,"The most convenient one is to create a\n",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://memgraph.com/docs/memgraph/reference-guide/triggers"},"trigger"))," so\nthat every time an edge is added to the graph, the trigger calls the procedure\nand makes an update."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE TRIGGER create_embeddings ON --\x3e CREATE BEFORE COMMIT\nEXECUTE CALL tgn.update(createdEdges) RETURN 1;\n")),(0,r.kt)("p",null,"The second option is to add all the edges and then call the algorithm with them:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"MATCH (n)-[e]->(m)\nWITH COLLECT(e) as edges\nCALL tgn.update(edges) RETURN 1;\n")),(0,r.kt)("h3",{id:"get"},(0,r.kt)("inlineCode",{parentName:"h3"},"get()")),(0,r.kt)("p",null,"Get calculated embeddings for each vertex."),(0,r.kt)("h4",{id:"output"},"Output:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"node: mgp.Vertex")," \u27a1 Vertex (node) in Memgraph."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"embedding: mgp.List[float]")," \u27a1 Low-dimensional representation of node in form\nof graph embedding.")),(0,r.kt)("h4",{id:"usage-3"},"Usage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.get() YIELD * RETURN *;\n")),(0,r.kt)("h3",{id:"set_eval"},(0,r.kt)("inlineCode",{parentName:"h3"},"set_eval()")),(0,r.kt)("p",null,"Change ",(0,r.kt)("strong",{parentName:"p"},"TGN")," mode to ",(0,r.kt)("inlineCode",{parentName:"p"},"eval"),"."),(0,r.kt)("h4",{id:"usage-4"},"Usage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.set_eval() YIELD *;\n")),(0,r.kt)("h3",{id:"get_results"},(0,r.kt)("inlineCode",{parentName:"h3"},"get_results()")),(0,r.kt)("p",null,"This method will return ",(0,r.kt)("inlineCode",{parentName:"p"},"results")," for every batch you did ",(0,r.kt)("inlineCode",{parentName:"p"},"train")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"eval")," on,\nas well as ",(0,r.kt)("inlineCode",{parentName:"p"},"average_precision"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"batch_process_time"),". Epoch count starts\nfrom 1."),(0,r.kt)("h4",{id:"output-1"},"Output:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"epoch_num:mgp.Number")," \u27a1 The number of ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," epochs."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"batch_num:mgp.Number")," \u27a1 The number of batches per ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," epoch."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"batch_process_time:mgp.Number")," \u27a1 Time needed to process a batch."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"average_precision:mgp.Number")," \u27a1 Mean average precision on the current batch."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"batch_type:string")," \u27a1 A string indicating whether ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," is performed\non the batch.")),(0,r.kt)("h4",{id:"usage-5"},"Usage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.get_results() YIELD * RETURN *;\n")),(0,r.kt)("h3",{id:"train_and_evalnum_epochs"},(0,r.kt)("inlineCode",{parentName:"h3"},"train_and_eval(num_epochs)")),(0,r.kt)("p",null,"The purpose of this method is to do additional training rounds on ",(0,r.kt)("inlineCode",{parentName:"p"},"train")," edges\nand ",(0,r.kt)("inlineCode",{parentName:"p"},"eval")," on evaluation edges."),(0,r.kt)("h4",{id:"input-2"},"Input:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"num_epochs: integer")," \u27a1 Perform additional epoch training and evaluation ",(0,r.kt)("strong",{parentName:"li"},"after"),"\nthe stream is done.")),(0,r.kt)("h4",{id:"output-2"},"Output:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"epoch_num: integer")," \u27a1 The epoch of the batch for which performance statistics\nwill be returned."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"batch_num: integer")," \u27a1 The number of the batch for which performance statistics\nwill be returned."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"batch_process_time: float")," \u27a1 Processing time in seconds for a batch."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"average_precision:mgp.Number")," \u27a1 Mean average precision on the current batch."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"batch_type:string")," \u27a1 Whether we performed ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"eval")," on the batch.")),(0,r.kt)("h4",{id:"usage-6"},"Usage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.train_and_eval(10) YIELD * RETURN *;\n")),(0,r.kt)("h3",{id:"predict_link_scorevertex_1-vertex_2"},(0,r.kt)("inlineCode",{parentName:"h3"},"predict_link_score(vertex_1, vertex_2)")),(0,r.kt)("p",null,"The purpose of this method is to get the link prediction score for two vertices in graph if you have been\ntraining ",(0,r.kt)("inlineCode",{parentName:"p"},"TGN")," for the link prediction task."),(0,r.kt)("h4",{id:"input-3"},"Input:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"src: mgp.Vertex")," \u27a1 Source vertex of the link prediction"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"dest: mgp.Vertex")," \u27a1 Destination vertex of the link prediction")),(0,r.kt)("h4",{id:"output-3"},"Output:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"prediction: mgp.Number")," \u27a1 Float number between 0 and 1, likelihood of link between ",(0,r.kt)("inlineCode",{parentName:"li"},"source")," vertex and ",(0,r.kt)("inlineCode",{parentName:"li"},"destination"),"\nvertex.")),(0,r.kt)("h4",{id:"usage-7"},"Usage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"MATCH (n:User)\nWITH n\nLIMIT 1\nMATCH (m:Item)\nOPTIONAL MATCH  (n)-[r]->(m)\n  WHERE r is null\nCALL tgn.predict_link_score(n,m) YIELD *\nRETURN n,m, prediction;\n")),(0,r.kt)("h2",{id:"example"},"Example"),(0,r.kt)(l.Z,{groupId:"example",defaultValue:"visualization",values:[{label:"Step 1: Input graph",value:"visualization"},{label:"Step 2: Set parameters",value:"cypher-param-set"},{label:"Step 3: Set trigger",value:"cypher-trigger-set"},{label:"Step 4: Load training batch",value:"cypher-train-load"},{label:"Step 5: Change mode",value:"cypher-mode-change"},{label:"Step 6: Load evaluation batch",value:"cypher-eval-load"},{label:"Step 7: Train epochs",value:"cypher-epoch-train"},{label:"Step 8: Run",value:"run"},{label:"Step 9: Results",value:"result"}],mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"visualization",mdxType:"TabItem"},(0,r.kt)("img",{src:a(59871).Z})),(0,r.kt)(i.Z,{value:"cypher-param-set",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.set_params({learning_type:'self_supervised', batch_size:2, num_of_layers:1,\n                      layer_type:'graph_attn',memory_dimension:100, time_dimension:100,\n                      num_edge_features:20, num_node_features:20, message_dimension:100,\n                      num_neighbors:10, edge_message_function_type:'identity',\n                      message_aggregator_type:'last', memory_updater_type:'gru', num_attention_heads:1});\n"))),(0,r.kt)(i.Z,{value:"cypher-trigger-set",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CREATE TRIGGER create_embeddings ON --\x3e CREATE BEFORE COMMIT\nEXECUTE CALL tgn.update(createdEdges) RETURN 1;\n"))),(0,r.kt)(i.Z,{value:"cypher-train-load",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"MERGE (n:Node {id: 1}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 2}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 10}) MERGE (m:Node {id: 5}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 5}) MERGE (m:Node {id: 2}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 9}) MERGE (m:Node {id: 7}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 7}) MERGE (m:Node {id: 3}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 3}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 9}) MERGE (m:Node {id: 8}) CREATE (n)-[:RELATION]->(m);\n"))),(0,r.kt)(i.Z,{value:"cypher-mode-change",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"CALL tgn.set_eval() YIELD *;\n\n"))),(0,r.kt)(i.Z,{value:"cypher-eval-load",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"},"MERGE (n:Node {id: 8}) MERGE (m:Node {id: 4}) CREATE (n)-[:RELATION]->(m);\nMERGE (n:Node {id: 4}) MERGE (m:Node {id: 6}) CREATE (n)-[:RELATION]->(m);\n"))),(0,r.kt)(i.Z,{value:"cypher-epoch-train",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"}," CALL tgn.train_and_eval(5) YIELD *\n"))),(0,r.kt)(i.Z,{value:"run",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cypher"}," CALL tgn.get_results() YIELD  epoch_num, batch_num, average_precision, batch_process_time, batch_type\n RETURN epoch_num, batch_num, average_precision, batch_type, batch_process_time;\n"))),(0,r.kt)(i.Z,{value:"result",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plaintext"},'+--------------------+--------------------+--------------------+--------------------+--------------------+\n| epoch_num          | batch_num          | average_precision  | batch_type         | batch_process_time |\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n| 1                  | 1                  | 0.5                | "Train"            | 0.05               |\n| 1                  | 2                  | 0.42               | "Eval"             | 0.02               |\n| 2                  | 1                  | 0.83               | "Train"            | 0.03               |\n| 2                  | 2                  | 0.5                | "Train"            | 0.04               |\n| 2                  | 3                  | 0.5                | "Train"            | 0.04               |\n| 2                  | 4                  | 0.58               | "Train"            | 0.04               |\n| 2                  | 5                  | 0.83               | "Eval"             | 0.02               |\n| 3                  | 1                  | 0.5                | "Train"            | 0.03               |\n| 3                  | 2                  | 0.75               | "Train"            | 0.03               |\n| 3                  | 3                  | 0.83               | "Train"            | 0.03               |\n| 3                  | 4                  | 1                  | "Train"            | 0.04               |\n| 3                  | 5                  | 0.83               | "Eval"             | 0.02               |\n| 4                  | 1                  | 0.5                | "Train"            | 0.03               |\n| 4                  | 2                  | 0.58               | "Train"            | 0.03               |\n| 4                  | 3                  | 1                  | "Train"            | 0.03               |\n| 4                  | 4                  | 1                  | "Train"            | 0.04               |\n| 4                  | 5                  | 1                  | "Eval"             | 0.02               |\n| 5                  | 1                  | 0.83               | "Train"            | 0.03               |\n| 5                  | 2                  | 0.58               | "Train"            | 0.03               |\n| 5                  | 3                  | 1                  | "Train"            | 0.03               |\n| 5                  | 4                  | 1                  | "Train"            | 0.03               |\n| 5                  | 5                  | 0.83               | "Eval"             | 0.02               |\n| 6                  | 1                  | 0.58               | "Train"            | 0.03               |\n| 6                  | 2                  | 0.83               | "Train"            | 0.03               |\n| 6                  | 3                  | 1                  | "Train"            | 0.03               |\n| 6                  | 4                  | 1                  | "Train"            | 0.03               |\n| 6                  | 5                  | 1                  | "Eval"             | 0.01               |\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n')))))}k.isMDXComponent=!0},83523:(e,t,a)=>{a.d(t,{ZP:()=>i});var n=a(87462),r=(a(67294),a(3905));const l={toc:[]};function i(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},l,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"If you want to execute this algorithm on graph projections, subgraphs or portions\nof the graph, be sure to check out the guide on\n",(0,r.kt)("a",{parentName:"p",href:"/mage/how-to-guides/run-a-subgraph-module"},"How to run a MAGE module on subgraphs"),".")))}i.isMDXComponent=!0},85162:(e,t,a)=>{a.d(t,{Z:()=>i});var n=a(67294),r=a(86010);const l="tabItem_Ymn6";function i(e){let{children:t,hidden:a,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(l,i),hidden:a},t)}},65488:(e,t,a)=>{a.d(t,{Z:()=>g});var n=a(87462),r=a(67294),l=a(86010),i=a(72389),o=a(67392),p=a(7094),s=a(12466);const m="tabList__CuJ",d="tabItem_LNqP";function u(e){var t;const{lazy:a,block:i,defaultValue:u,values:g,groupId:c,className:k}=e,h=r.Children.map(e.children,(e=>{if((0,r.isValidElement)(e)&&"value"in e.props)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})),N=g??h.map((e=>{let{props:{value:t,label:a,attributes:n}}=e;return{value:t,label:a,attributes:n}})),y=(0,o.l)(N,((e,t)=>e.value===t.value));if(y.length>0)throw new Error(`Docusaurus error: Duplicate values "${y.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`);const f=null===u?u:u??(null==(t=h.find((e=>e.props.default)))?void 0:t.props.value)??h[0].props.value;if(null!==f&&!N.some((e=>e.value===f)))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${f}" but none of its children has the corresponding value. Available values are: ${N.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);const{tabGroupChoices:b,setTabGroupChoices:v}=(0,p.U)(),[_,T]=(0,r.useState)(f),w=[],{blockElementScrollPositionUntilNextRender:E}=(0,s.o5)();if(null!=c){const e=b[c];null!=e&&e!==_&&N.some((t=>t.value===e))&&T(e)}const C=e=>{const t=e.currentTarget,a=w.indexOf(t),n=N[a].value;n!==_&&(E(t),T(n),null!=c&&v(c,String(n)))},x=e=>{var t;let a=null;switch(e.key){case"Enter":C(e);break;case"ArrowRight":{const t=w.indexOf(e.currentTarget)+1;a=w[t]??w[0];break}case"ArrowLeft":{const t=w.indexOf(e.currentTarget)-1;a=w[t]??w[w.length-1];break}}null==(t=a)||t.focus()};return r.createElement("div",{className:(0,l.Z)("tabs-container",m)},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":i},k)},N.map((e=>{let{value:t,label:a,attributes:i}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:_===t?0:-1,"aria-selected":_===t,key:t,ref:e=>w.push(e),onKeyDown:x,onClick:C},i,{className:(0,l.Z)("tabs__item",d,null==i?void 0:i.className,{"tabs__item--active":_===t})}),a??t)}))),a?(0,r.cloneElement)(h.filter((e=>e.props.value===_))[0],{className:"margin-top--md"}):r.createElement("div",{className:"margin-top--md"},h.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==_})))))}function g(e){const t=(0,i.Z)();return r.createElement(u,(0,n.Z)({key:String(t)},e))}},59871:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/graph_visualization-387a6a6a1fbd6a6872f7f727ee3706d8.png"}}]);